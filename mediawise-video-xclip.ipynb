{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8440577,"sourceType":"datasetVersion","datasetId":5028208},{"sourceId":8440583,"sourceType":"datasetVersion","datasetId":5028214},{"sourceId":8440615,"sourceType":"datasetVersion","datasetId":5028241},{"sourceId":8440621,"sourceType":"datasetVersion","datasetId":5028247},{"sourceId":8440627,"sourceType":"datasetVersion","datasetId":5028251},{"sourceId":8440642,"sourceType":"datasetVersion","datasetId":5028263},{"sourceId":8440666,"sourceType":"datasetVersion","datasetId":5028283},{"sourceId":8440676,"sourceType":"datasetVersion","datasetId":5028291},{"sourceId":8440678,"sourceType":"datasetVersion","datasetId":5028293},{"sourceId":8440777,"sourceType":"datasetVersion","datasetId":5028369},{"sourceId":8440871,"sourceType":"datasetVersion","datasetId":5028447},{"sourceId":8440883,"sourceType":"datasetVersion","datasetId":5028457},{"sourceId":8440891,"sourceType":"datasetVersion","datasetId":5028464},{"sourceId":8440893,"sourceType":"datasetVersion","datasetId":5028466},{"sourceId":8440897,"sourceType":"datasetVersion","datasetId":5028469},{"sourceId":8440939,"sourceType":"datasetVersion","datasetId":5028504},{"sourceId":8440941,"sourceType":"datasetVersion","datasetId":5028505},{"sourceId":8441017,"sourceType":"datasetVersion","datasetId":5028564},{"sourceId":8441018,"sourceType":"datasetVersion","datasetId":5028565}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-17T23:04:19.102233Z","iopub.execute_input":"2024-05-17T23:04:19.102876Z","iopub.status.idle":"2024-05-17T23:04:22.906054Z","shell.execute_reply.started":"2024-05-17T23:04:19.102845Z","shell.execute_reply":"2024-05-17T23:04:22.905005Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/hack-chunk-desc/train_segments.csv')","metadata":{"execution":{"iopub.status.busy":"2024-05-17T23:04:22.908326Z","iopub.execute_input":"2024-05-17T23:04:22.908817Z","iopub.status.idle":"2024-05-17T23:04:22.944326Z","shell.execute_reply.started":"2024-05-17T23:04:22.908783Z","shell.execute_reply":"2024-05-17T23:04:22.943318Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-05-17T23:04:22.946127Z","iopub.execute_input":"2024-05-17T23:04:22.946446Z","iopub.status.idle":"2024-05-17T23:04:22.975936Z","shell.execute_reply.started":"2024-05-17T23:04:22.946419Z","shell.execute_reply":"2024-05-17T23:04:22.974743Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"       Advertisement ID  Segment_num\n0               1831845           16\n1               4467135           11\n2               2285593            0\n3               3825366            0\n4               2313008            0\n...                 ...          ...\n17735           4299761            1\n17736           2298577            0\n17737           4018035            1\n17738           3922868            0\n17739           4527298            7\n\n[17740 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Advertisement ID</th>\n      <th>Segment_num</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1831845</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4467135</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2285593</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3825366</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2313008</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>17735</th>\n      <td>4299761</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17736</th>\n      <td>2298577</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17737</th>\n      <td>4018035</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17738</th>\n      <td>3922868</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17739</th>\n      <td>4527298</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n<p>17740 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"segments = pd.read_excel('/kaggle/input/hack-chunk-desc/segment_dict.xlsx')","metadata":{"execution":{"iopub.status.busy":"2024-05-17T23:04:22.978173Z","iopub.execute_input":"2024-05-17T23:04:22.978607Z","iopub.status.idle":"2024-05-17T23:04:23.747065Z","shell.execute_reply.started":"2024-05-17T23:04:22.978564Z","shell.execute_reply":"2024-05-17T23:04:23.745912Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import os\n\nall_files = []\nbase_path = '/kaggle/input/hack-chunk-'\n\nfor i in ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10-stranger', '11', '12-stranger', '13', '14', '15', '16', '17'):\n    folder_path = f\"{base_path}{i}\"\n    for root, dirs, files in os.walk(folder_path):\n        for file in files:\n            full_path = os.path.join(root, file)\n            all_files.append(full_path)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T23:04:23.749198Z","iopub.execute_input":"2024-05-17T23:04:23.749783Z","iopub.status.idle":"2024-05-17T23:04:26.039949Z","shell.execute_reply.started":"2024-05-17T23:04:23.749745Z","shell.execute_reply":"2024-05-17T23:04:26.039078Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"id_to_path = {}\nfor file_path in all_files:\n    file_id = int(file_path.split('/')[-1].split('.')[0])\n    id_to_path[file_id] = file_path\n\ndef get_path(ad_id):\n    return id_to_path.get(ad_id, None)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T23:04:26.042000Z","iopub.execute_input":"2024-05-17T23:04:26.042328Z","iopub.status.idle":"2024-05-17T23:04:26.069398Z","shell.execute_reply.started":"2024-05-17T23:04:26.042301Z","shell.execute_reply":"2024-05-17T23:04:26.068319Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df['path'] = df['Advertisement ID'].apply(get_path)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T23:04:26.070626Z","iopub.execute_input":"2024-05-17T23:04:26.070963Z","iopub.status.idle":"2024-05-17T23:04:26.093267Z","shell.execute_reply.started":"2024-05-17T23:04:26.070933Z","shell.execute_reply":"2024-05-17T23:04:26.092278Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-05-17T23:04:26.094594Z","iopub.execute_input":"2024-05-17T23:04:26.094951Z","iopub.status.idle":"2024-05-17T23:04:26.111498Z","shell.execute_reply.started":"2024-05-17T23:04:26.094918Z","shell.execute_reply":"2024-05-17T23:04:26.110484Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"       Advertisement ID  Segment_num  \\\n0               1831845           16   \n1               4467135           11   \n2               2285593            0   \n3               3825366            0   \n4               2313008            0   \n...                 ...          ...   \n17735           4299761            1   \n17736           2298577            0   \n17737           4018035            1   \n17738           3922868            0   \n17739           4527298            7   \n\n                                                    path  \n0               /kaggle/input/hack-chunk-2/2/1831845.mp4  \n1             /kaggle/input/hack-chunk-16/16/4467135.avi  \n2               /kaggle/input/hack-chunk-5/5/2285593.wav  \n3               /kaggle/input/hack-chunk-8/8/3825366.avi  \n4               /kaggle/input/hack-chunk-6/6/2313008.wav  \n...                                                  ...  \n17735         /kaggle/input/hack-chunk-16/16/4299761.avi  \n17736           /kaggle/input/hack-chunk-5/5/2298577.wav  \n17737  /kaggle/input/hack-chunk-10-stranger/10/401803...  \n17738           /kaggle/input/hack-chunk-9/9/3922868.avi  \n17739         /kaggle/input/hack-chunk-17/17/4527298.avi  \n\n[17740 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Advertisement ID</th>\n      <th>Segment_num</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1831845</td>\n      <td>16</td>\n      <td>/kaggle/input/hack-chunk-2/2/1831845.mp4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4467135</td>\n      <td>11</td>\n      <td>/kaggle/input/hack-chunk-16/16/4467135.avi</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2285593</td>\n      <td>0</td>\n      <td>/kaggle/input/hack-chunk-5/5/2285593.wav</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3825366</td>\n      <td>0</td>\n      <td>/kaggle/input/hack-chunk-8/8/3825366.avi</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2313008</td>\n      <td>0</td>\n      <td>/kaggle/input/hack-chunk-6/6/2313008.wav</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>17735</th>\n      <td>4299761</td>\n      <td>1</td>\n      <td>/kaggle/input/hack-chunk-16/16/4299761.avi</td>\n    </tr>\n    <tr>\n      <th>17736</th>\n      <td>2298577</td>\n      <td>0</td>\n      <td>/kaggle/input/hack-chunk-5/5/2298577.wav</td>\n    </tr>\n    <tr>\n      <th>17737</th>\n      <td>4018035</td>\n      <td>1</td>\n      <td>/kaggle/input/hack-chunk-10-stranger/10/401803...</td>\n    </tr>\n    <tr>\n      <th>17738</th>\n      <td>3922868</td>\n      <td>0</td>\n      <td>/kaggle/input/hack-chunk-9/9/3922868.avi</td>\n    </tr>\n    <tr>\n      <th>17739</th>\n      <td>4527298</td>\n      <td>7</td>\n      <td>/kaggle/input/hack-chunk-17/17/4527298.avi</td>\n    </tr>\n  </tbody>\n</table>\n<p>17740 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df = df[~df['path'].str.endswith('.jpg')]\ndf = df[~df['path'].str.endswith('.wav')]","metadata":{"execution":{"iopub.status.busy":"2024-05-17T23:04:26.113008Z","iopub.execute_input":"2024-05-17T23:04:26.113377Z","iopub.status.idle":"2024-05-17T23:04:26.143811Z","shell.execute_reply.started":"2024-05-17T23:04:26.113346Z","shell.execute_reply":"2024-05-17T23:04:26.142976Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-05-17T23:04:26.144894Z","iopub.execute_input":"2024-05-17T23:04:26.145201Z","iopub.status.idle":"2024-05-17T23:04:26.156035Z","shell.execute_reply.started":"2024-05-17T23:04:26.145167Z","shell.execute_reply":"2024-05-17T23:04:26.155021Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"       Advertisement ID  Segment_num  \\\n0               1831845           16   \n1               4467135           11   \n3               3825366            0   \n5               3959329            0   \n6               4321218            1   \n...                 ...          ...   \n17734           4227145            1   \n17735           4299761            1   \n17737           4018035            1   \n17738           3922868            0   \n17739           4527298            7   \n\n                                                    path  \n0               /kaggle/input/hack-chunk-2/2/1831845.mp4  \n1             /kaggle/input/hack-chunk-16/16/4467135.avi  \n3               /kaggle/input/hack-chunk-8/8/3825366.avi  \n5               /kaggle/input/hack-chunk-9/9/3959329.avi  \n6             /kaggle/input/hack-chunk-16/16/4321218.avi  \n...                                                  ...  \n17734         /kaggle/input/hack-chunk-14/14/4227145.avi  \n17735         /kaggle/input/hack-chunk-16/16/4299761.avi  \n17737  /kaggle/input/hack-chunk-10-stranger/10/401803...  \n17738           /kaggle/input/hack-chunk-9/9/3922868.avi  \n17739         /kaggle/input/hack-chunk-17/17/4527298.avi  \n\n[14189 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Advertisement ID</th>\n      <th>Segment_num</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1831845</td>\n      <td>16</td>\n      <td>/kaggle/input/hack-chunk-2/2/1831845.mp4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4467135</td>\n      <td>11</td>\n      <td>/kaggle/input/hack-chunk-16/16/4467135.avi</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3825366</td>\n      <td>0</td>\n      <td>/kaggle/input/hack-chunk-8/8/3825366.avi</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3959329</td>\n      <td>0</td>\n      <td>/kaggle/input/hack-chunk-9/9/3959329.avi</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>4321218</td>\n      <td>1</td>\n      <td>/kaggle/input/hack-chunk-16/16/4321218.avi</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>17734</th>\n      <td>4227145</td>\n      <td>1</td>\n      <td>/kaggle/input/hack-chunk-14/14/4227145.avi</td>\n    </tr>\n    <tr>\n      <th>17735</th>\n      <td>4299761</td>\n      <td>1</td>\n      <td>/kaggle/input/hack-chunk-16/16/4299761.avi</td>\n    </tr>\n    <tr>\n      <th>17737</th>\n      <td>4018035</td>\n      <td>1</td>\n      <td>/kaggle/input/hack-chunk-10-stranger/10/401803...</td>\n    </tr>\n    <tr>\n      <th>17738</th>\n      <td>3922868</td>\n      <td>0</td>\n      <td>/kaggle/input/hack-chunk-9/9/3922868.avi</td>\n    </tr>\n    <tr>\n      <th>17739</th>\n      <td>4527298</td>\n      <td>7</td>\n      <td>/kaggle/input/hack-chunk-17/17/4527298.avi</td>\n    </tr>\n  </tbody>\n</table>\n<p>14189 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"video_path = df.path[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-17T23:04:26.324203Z","iopub.execute_input":"2024-05-17T23:04:26.324861Z","iopub.status.idle":"2024-05-17T23:04:26.332112Z","shell.execute_reply.started":"2024-05-17T23:04:26.324829Z","shell.execute_reply":"2024-05-17T23:04:26.331265Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"! pip install av","metadata":{"execution":{"iopub.status.busy":"2024-05-17T23:04:26.882890Z","iopub.execute_input":"2024-05-17T23:04:26.883255Z","iopub.status.idle":"2024-05-17T23:04:44.390725Z","shell.execute_reply.started":"2024-05-17T23:04:26.883212Z","shell.execute_reply":"2024-05-17T23:04:44.389718Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Collecting av\n  Downloading av-12.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\nDownloading av-12.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: av\nSuccessfully installed av-12.0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import av\nimport torch\nimport numpy as np\nfrom transformers import AutoProcessor, AutoModel\nfrom huggingface_hub import hf_hub_download\n\nnp.random.seed(42)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T23:04:44.392750Z","iopub.execute_input":"2024-05-17T23:04:44.393048Z","iopub.status.idle":"2024-05-17T23:05:10.483836Z","shell.execute_reply.started":"2024-05-17T23:04:44.393021Z","shell.execute_reply":"2024-05-17T23:05:10.482774Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"2024-05-17 23:04:58.083650: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-17 23:04:58.083776: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-17 23:04:58.356534: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"def read_video_pyav(container, indices):\n    frames = []\n    container.seek(0)\n    start_index = indices[0]\n    end_index = indices[-1]\n\n    for i, frame in enumerate(container.decode(video=0)):\n        if i > end_index:\n            break\n        if i >= start_index and i in indices:\n            frames.append(frame)\n\n    return np.stack([x.to_ndarray(format=\"rgb24\") for x in frames])\n\n\ndef sample_frame_indices(clip_len, frame_sample_rate, seg_len):\n    converted_len = int(clip_len * frame_sample_rate)\n    end_idx = np.random.randint(converted_len, seg_len)\n    start_idx = end_idx - converted_len\n    indices = np.linspace(start_idx, end_idx, num=clip_len)\n    indices = np.clip(indices, start_idx, end_idx - 1).astype(np.int64)\n\n    return indices","metadata":{"execution":{"iopub.status.busy":"2024-05-17T23:05:10.485188Z","iopub.execute_input":"2024-05-17T23:05:10.485835Z","iopub.status.idle":"2024-05-17T23:05:10.494601Z","shell.execute_reply.started":"2024-05-17T23:05:10.485805Z","shell.execute_reply":"2024-05-17T23:05:10.493643Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"processor = AutoProcessor.from_pretrained(\"microsoft/xclip-base-patch32\")\nmodel = AutoModel.from_pretrained(\"microsoft/xclip-base-patch32\")\nmodel.to('cuda')","metadata":{"execution":{"iopub.status.busy":"2024-05-17T23:05:10.496524Z","iopub.execute_input":"2024-05-17T23:05:10.496836Z","iopub.status.idle":"2024-05-17T23:05:19.569710Z","shell.execute_reply.started":"2024-05-17T23:05:10.496810Z","shell.execute_reply":"2024-05-17T23:05:19.568778Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/309 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6959c07568374e6da184d8ea76b7f812"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/965 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fc51b9b35574434a32247f25fa5a994"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/862k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1058013929d544f6a4cd60805bd75ffd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c365860e2bf4a56bb27ee56f52b0c4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.22M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"400e0e65d0594cacbd74d58931c78dcb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"728aeec594e147c2b973619493faf526"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/4.72k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92316b7a281a4a1d81a17690fec12da7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/786M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45951ceea33b4e75bf186b7449e502b5"}},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"XCLIPModel(\n  (text_model): XCLIPTextTransformer(\n    (embeddings): XCLIPTextEmbeddings(\n      (token_embedding): Embedding(49408, 512)\n      (position_embedding): Embedding(77, 512)\n    )\n    (encoder): XCLIPEncoder(\n      (layers): ModuleList(\n        (0-11): 12 x XCLIPEncoderLayer(\n          (self_attn): XCLIPAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (mlp): XCLIPMLP(\n            (activation_fn): QuickGELUActivation()\n            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          )\n          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n  )\n  (vision_model): XCLIPVisionTransformer(\n    (embeddings): XCLIPVisionEmbeddings(\n      (patch_embedding): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n      (position_embedding): Embedding(50, 768)\n    )\n    (pre_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    (encoder): XCLIPVisionEncoder(\n      (layers): ModuleList(\n        (0-11): 12 x XCLIPVisionEncoderLayer(\n          (message_fc): Linear(in_features=768, out_features=768, bias=True)\n          (message_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (message_attn): XCLIPAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (drop_path): Identity()\n          (self_attn): XCLIPAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (mlp): XCLIPMLP(\n            (activation_fn): QuickGELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n    (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (visual_projection): Linear(in_features=768, out_features=512, bias=False)\n  (text_projection): Linear(in_features=512, out_features=512, bias=False)\n  (prompts_visual_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  (mit): XCLIPMultiframeIntegrationTransformer(\n    (encoder): XCLIPEncoder(\n      (layers): ModuleList(\n        (0): XCLIPEncoderLayer(\n          (self_attn): XCLIPAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (mlp): XCLIPMLP(\n            (activation_fn): QuickGELUActivation()\n            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          )\n          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (prompts_generator): XCLIPPromptGenerator(\n    (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (decoder): ModuleList(\n      (0-1): 2 x PromptGeneratorLayer(\n        (cross_attn): XCLIPCrossAttention(\n          (q_proj): Linear(in_features=512, out_features=512, bias=False)\n          (k_proj): Linear(in_features=512, out_features=512, bias=False)\n          (v_proj): Linear(in_features=512, out_features=512, bias=False)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): QuickGELUActivation()\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=2048, out_features=512, bias=True)\n        )\n      )\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"import cv2\n\ndef get_video_frames(video_path, frame_indices):\n    cap = cv2.VideoCapture(video_path)\n    if not cap.isOpened():\n        print(f\"Error opening video file '{video_path}'\")\n        return None\n    \n    frames = []\n    for i in range(max(frame_indices) + 1):\n        ret, frame = cap.read()\n        if not ret:\n            break\n        if i in frame_indices:\n            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n            frames.append(frame_rgb)\n\n    cap.release()\n    return frames","metadata":{"execution":{"iopub.status.busy":"2024-05-17T23:05:19.570727Z","iopub.execute_input":"2024-05-17T23:05:19.570992Z","iopub.status.idle":"2024-05-17T23:05:19.997062Z","shell.execute_reply.started":"2024-05-17T23:05:19.570969Z","shell.execute_reply":"2024-05-17T23:05:19.996291Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def getFeatures(video_path):\n    cap = cv2.VideoCapture(video_path)\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    cap.release()\n    \n    indices = sample_frame_indices(clip_len=8, frame_sample_rate=1, seg_len=total_frames)\n    video = get_video_frames(video_path, indices)\n    \n#     container = av.open(video_path)\n#     indices = sample_frame_indices(clip_len=8, frame_sample_rate=1, seg_len=container.streams.video[0].frames)\n#     video = read_video_pyav(container, indices)\n\n    inputs = processor(videos=list(video), return_tensors=\"pt\").to('cuda')\n    video_features = model.get_video_features(**inputs)\n    \n    return video_features","metadata":{"execution":{"iopub.status.busy":"2024-05-17T23:05:19.998145Z","iopub.execute_input":"2024-05-17T23:05:19.998447Z","iopub.status.idle":"2024-05-17T23:05:20.004609Z","shell.execute_reply.started":"2024-05-17T23:05:19.998422Z","shell.execute_reply":"2024-05-17T23:05:20.003734Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"%%time\n\ngetFeatures(video_path)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T23:05:29.750236Z","iopub.execute_input":"2024-05-17T23:05:29.751120Z","iopub.status.idle":"2024-05-17T23:05:30.284461Z","shell.execute_reply.started":"2024-05-17T23:05:29.751090Z","shell.execute_reply":"2024-05-17T23:05:30.283483Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"CPU times: user 595 ms, sys: 23 ms, total: 618 ms\nWall time: 495 ms\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"tensor([[ 7.8191e-01,  5.1898e-01, -7.5805e-01,  1.1337e-01,  1.0243e+00,\n          1.5079e+00,  1.1141e+00, -1.9796e-01, -2.5370e-01,  3.4517e-01,\n         -1.6048e+00, -8.3887e-01,  9.8123e-01,  1.0655e+00, -4.9804e-01,\n         -7.8853e-01, -6.9780e-02, -2.5378e+00, -1.1338e+00, -1.4271e+00,\n          1.1018e+00, -2.8242e-01, -7.7482e-01, -1.2295e+00, -6.1210e-01,\n         -7.2688e-01,  1.3268e+00, -1.3197e+00, -7.2198e-01,  5.9427e-01,\n          6.6152e-01, -1.8110e+00,  4.4741e-01,  9.8989e-01,  5.7662e-02,\n         -9.8387e-01, -1.1376e+00, -1.8527e+00, -5.7001e-02,  6.6424e-01,\n         -8.7053e-01,  1.3028e+00,  6.6109e-01,  1.7643e-01,  6.0742e-01,\n         -2.4312e-01,  4.0821e-01, -7.5161e-02, -1.1192e+00, -1.2909e+00,\n          9.8022e-01, -5.2709e-01, -3.8893e-01,  2.6255e-01,  6.3190e-01,\n         -2.5669e-01,  5.7268e-01,  9.4662e-01,  1.3667e+00,  4.4056e-01,\n         -3.6849e-03, -1.9191e+00,  3.6598e-01,  8.9066e-02, -2.2522e-01,\n         -1.3970e+00, -4.5285e-01, -1.0794e+00,  7.9791e-01,  2.9260e-01,\n         -3.3214e-01,  1.7356e-01, -6.5352e-01,  8.4333e-01, -5.5988e-01,\n         -7.9366e-01, -1.1801e+00,  1.6869e+00,  9.4003e-01,  9.0050e-01,\n          4.1700e-01, -1.2752e-01,  1.2953e+00, -6.8111e-01, -3.1184e-01,\n         -1.2853e+00,  7.8330e-01,  6.2679e-02,  7.7791e-01,  6.9987e-01,\n         -6.1173e-02,  8.0080e-01, -5.5555e+00, -9.7282e-01,  8.4802e-02,\n          2.0319e-01,  1.9443e-01,  3.8647e-01,  1.0352e+00, -6.3655e-02,\n         -1.8166e-01, -1.2688e+00,  7.1547e-02,  1.9994e-01,  9.5386e-01,\n         -1.4960e-01, -2.8727e+00, -7.5014e-01,  2.7505e-03, -4.2165e-01,\n          1.2704e+00,  1.3459e+00, -1.8819e-01, -8.0251e-01, -1.2160e+00,\n          7.7824e-01, -4.8785e-01, -1.2263e+00,  2.2174e+00, -5.8236e-01,\n          4.8449e-01,  1.2242e-01,  9.5112e-01, -3.8517e-01, -8.2116e-01,\n         -4.3142e-01, -4.0458e-01,  4.7648e-01, -6.8708e-01, -4.8257e-01,\n         -2.0128e-01,  5.3674e-01,  3.2993e-01,  1.2048e+00, -1.1917e+00,\n          8.2993e-01, -6.9525e-02,  8.8551e-02, -7.7075e-01,  1.9554e-02,\n         -7.8520e-01,  3.9055e-01, -4.1426e-01,  7.8695e-01,  2.0850e-01,\n          1.3407e+00,  5.8418e-01,  1.6765e-03, -8.6988e-01,  1.9737e-01,\n         -9.5074e-01,  1.8337e-01, -1.2276e+00,  3.5631e-01,  2.0317e-01,\n         -1.6173e+00, -1.2912e-01, -6.3085e-01, -7.3129e-01, -5.6648e-01,\n          7.0087e-01, -1.1869e+00,  7.7785e-01, -8.5400e-01,  5.1285e-02,\n          1.5924e-01,  1.0895e-01, -1.0493e+00,  2.1072e-01, -1.1862e+00,\n          2.9968e-01, -8.6809e-01,  1.5259e+00, -4.7594e-01,  9.1849e-01,\n          5.2633e-01,  3.3206e-01,  5.0765e-01, -3.4245e-01,  6.6764e-01,\n          7.2076e-01,  9.4852e-01, -4.5608e-01,  8.0954e-01,  2.8262e-03,\n          1.0235e+00, -2.2513e-01, -6.8053e-01,  4.7402e-01,  1.8961e+00,\n         -4.7865e-01,  1.0593e-01,  1.4473e-02, -4.5555e-01, -9.7793e-01,\n          5.3731e-01, -6.2121e-01,  3.4611e-01,  7.1076e-01, -1.5822e+00,\n         -8.5366e-02,  1.0985e+00, -1.5840e-01,  1.7479e+00, -1.6715e+00,\n          4.2897e-01, -1.2716e+00, -2.1878e-01,  1.5991e+00,  6.6803e-01,\n          6.0503e-01,  9.3368e-02,  9.5270e-01,  4.3664e-01,  1.0705e-02,\n          1.0524e+00, -1.1139e+00, -6.7583e-01,  2.7908e+00,  8.1889e-01,\n          7.6015e-01, -1.9193e+00, -9.0818e-01, -5.1891e-01,  1.2749e+00,\n          3.2181e-01,  4.4310e-01,  1.0316e+00,  1.2228e+00, -6.4773e-01,\n         -1.1551e+00, -1.3990e+00,  2.0487e-01,  5.5841e-01,  9.6929e-01,\n          9.1443e-01,  9.6269e-02,  6.9428e-01, -1.1503e-01,  1.5605e-01,\n         -2.3492e-01,  1.3599e+00, -6.3304e-02, -1.4717e+00,  3.3235e-01,\n          9.7638e-01, -1.3722e+00, -1.9194e-01, -1.0886e+00,  1.1445e+00,\n          1.6046e-01, -8.4490e-01, -1.4063e+00, -1.2898e+00,  2.0094e+00,\n          6.0757e-01,  3.6475e-01,  6.7467e-01, -5.3958e-02, -8.9217e-01,\n         -3.2926e-01,  3.0644e-01, -6.7164e-01, -7.3108e-01, -1.5061e-01,\n         -9.3814e-01,  5.9639e-01,  1.4756e+00, -2.1947e+00, -1.7009e+00,\n         -7.6105e-01,  3.8579e-01,  9.1323e-01,  9.7551e-01, -8.7413e-01,\n          4.8265e-01, -1.8746e-01, -1.4640e+00,  2.0974e-02,  7.9108e-01,\n          1.9361e-01, -1.0039e+00,  7.1379e-02,  7.9413e-01, -7.9368e-01,\n          4.5422e-01,  9.5450e-01, -1.1691e+00, -1.6913e+00,  6.0948e-01,\n          8.9031e-01,  2.9499e-01, -2.1185e-01,  4.3968e-01, -3.7963e-02,\n          9.3366e-01, -6.4627e-01,  1.1550e+00, -7.7616e-01,  7.6446e-01,\n          7.6171e-01, -1.0338e+00,  1.2682e+00, -4.0695e-01, -1.0936e+00,\n          2.1472e-01,  9.7610e-01,  9.2898e-02,  1.2032e+00, -2.5046e-01,\n         -1.5473e-01, -2.6885e-01,  1.9074e+00, -1.6734e+00,  2.4214e-01,\n          5.5689e-01, -3.0704e-01,  3.4744e-02, -1.3665e+00,  8.1654e-01,\n         -1.9232e+00,  8.8313e-01,  1.2443e+00, -1.3956e-01, -6.1402e-01,\n          2.6641e-01, -3.1586e-01, -9.9996e-01, -1.2153e-01,  2.9799e-01,\n          4.8606e-01,  2.6710e-02,  1.3397e+00, -1.1462e+00,  2.8483e-01,\n         -1.5350e+00, -4.2459e-01,  3.0163e-01, -1.3360e+00, -1.2598e+00,\n         -2.0389e+00,  9.4048e-01,  2.1512e-01,  6.8648e-02,  1.0801e+00,\n          1.0335e+00, -3.8749e-01, -2.2791e-01, -1.0345e+00, -7.0670e-01,\n         -4.6203e-01,  1.0626e+00, -1.1861e+00,  1.2750e+00,  1.3936e-01,\n         -3.1292e-01,  1.2145e+00,  2.8814e+00,  5.0821e-01, -3.6950e-02,\n          6.8998e-01, -8.2201e-01,  1.4424e+00,  9.0756e-01, -9.3016e-01,\n         -8.5396e-01, -2.9446e-01,  8.5003e-02,  1.0396e+00, -1.2560e+00,\n         -3.7498e-01,  4.9058e-01, -2.8954e-02,  9.4326e-01,  2.7511e-01,\n         -4.7228e-01,  1.2562e-01, -1.6798e+00, -5.9761e-01,  2.2140e-01,\n          4.9338e-01,  4.8200e-01, -3.0218e-01,  1.0063e+00,  7.5399e-01,\n         -2.4572e-01, -8.2256e-01,  2.4040e-01,  6.4698e-01, -1.0929e-01,\n          7.4311e-01, -5.9445e-01,  4.4180e-01, -4.2050e-02,  8.7167e-01,\n         -8.6286e-01,  1.7376e+00,  4.1864e-01, -4.6856e-01, -2.5287e-01,\n         -6.5119e-01,  6.9952e-01,  2.9848e-01, -4.5391e-01,  2.9535e-02,\n          2.4519e-01,  8.6276e-01,  1.5048e+00, -6.6959e-01, -9.6534e-01,\n         -2.8672e-01, -3.7165e-01,  1.3097e+00,  1.4167e-01,  7.6566e-01,\n          1.7649e-01, -4.8162e-01, -9.8921e-01, -2.5643e-01,  9.3963e-01,\n          2.1723e-01,  1.7414e-01, -1.0122e+00,  7.6177e-01,  6.8381e-01,\n          4.9857e-01, -8.7015e-01, -1.0159e+00, -5.5521e+00,  9.1129e-01,\n          9.5552e-01, -1.3398e+00, -2.6432e+00, -2.0846e-01, -3.3346e-01,\n          6.6464e-01, -1.0604e+00, -2.0235e-02, -2.3794e-01, -7.3647e-02,\n          3.9647e-02, -7.0457e-01,  2.7448e-01, -6.3361e-01,  6.9513e-01,\n          8.4006e-02,  4.0333e-01,  1.5282e+00, -9.8147e-01, -3.5824e-01,\n         -4.5627e-01,  2.0599e+00, -1.5650e-02,  9.0950e-01,  8.8452e-01,\n         -3.6371e-01, -1.0508e+00, -1.0684e-01,  9.3594e-01, -9.7478e-01,\n         -8.6735e-02, -1.4199e+00, -4.1129e-01, -1.3331e+00,  2.2252e+00,\n          2.4128e-01, -7.2531e-03, -7.5075e-01, -1.0087e+00, -2.1790e-01,\n         -2.7261e-01,  1.4799e-01, -8.3182e-01, -5.8583e-01,  1.0026e+00,\n         -2.5149e-01, -9.0285e-01,  1.4058e-01,  9.9158e-01, -9.4904e-01,\n         -7.5873e-01, -1.2992e-01,  9.6723e-01, -1.1185e+00, -3.7915e-01,\n         -7.6574e-01, -6.1599e-01,  9.9950e-01, -1.4688e-02, -3.4336e-01,\n          2.9828e-01,  3.7840e-01, -2.8576e-01, -4.9461e-01, -2.9733e-01,\n         -7.2520e-01,  2.3660e-01, -3.7242e-01, -9.0886e-01,  5.8380e-01,\n          1.2662e+00,  2.9125e-01, -1.2433e-01, -5.0920e-01,  2.1588e-01,\n          4.9608e-01, -3.7566e-01,  6.6022e-01,  2.6799e-01, -3.0889e-02,\n          1.1347e-01, -1.0425e+00]], device='cuda:0', grad_fn=<MeanBackward1>)"},"metadata":{}}]},{"cell_type":"code","source":"# torch.Size([1, 512])","metadata":{"execution":{"iopub.status.busy":"2024-05-17T22:52:13.030610Z","iopub.status.idle":"2024-05-17T22:52:13.031256Z","shell.execute_reply.started":"2024-05-17T22:52:13.030966Z","shell.execute_reply":"2024-05-17T22:52:13.030989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.model_selection import train_test_split\n\nX = df.drop('Segment_num', axis=1)\ny = df['Segment_num']\n\nX_train, X_test_val, y_train, y_train_val = train_test_split(X, y, test_size=0.05, stratify=y, random_state=42)\nX_valid, X_test, y_valid, y_test = train_test_split(X_test_val, y_train_val, stratify=y_train_val, test_size=0.5, random_state=42)\n\nrus = RandomUnderSampler(random_state=42)\nX_res, y_res = rus.fit_resample(X_train, y_train)\n\ndf_train = pd.concat([X_res, y_res], axis=1)\ndf_val = pd.concat([X_valid, y_valid], axis=1)\ndf_test = pd.concat([X_test, y_test], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T23:05:36.586137Z","iopub.execute_input":"2024-05-17T23:05:36.586972Z","iopub.status.idle":"2024-05-17T23:05:37.503589Z","shell.execute_reply.started":"2024-05-17T23:05:36.586943Z","shell.execute_reply":"2024-05-17T23:05:37.502317Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"len(df_train)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T23:05:40.523982Z","iopub.execute_input":"2024-05-17T23:05:40.525324Z","iopub.status.idle":"2024-05-17T23:05:40.531072Z","shell.execute_reply.started":"2024-05-17T23:05:40.525286Z","shell.execute_reply":"2024-05-17T23:05:40.530077Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"1596"},"metadata":{}}]},{"cell_type":"code","source":"len(df_val)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T23:05:41.650496Z","iopub.execute_input":"2024-05-17T23:05:41.650911Z","iopub.status.idle":"2024-05-17T23:05:41.656896Z","shell.execute_reply.started":"2024-05-17T23:05:41.650883Z","shell.execute_reply":"2024-05-17T23:05:41.655960Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"355"},"metadata":{}}]},{"cell_type":"code","source":"len(df_test)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T23:05:42.198033Z","iopub.execute_input":"2024-05-17T23:05:42.198751Z","iopub.status.idle":"2024-05-17T23:05:42.204364Z","shell.execute_reply.started":"2024-05-17T23:05:42.198717Z","shell.execute_reply":"2024-05-17T23:05:42.203452Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"355"},"metadata":{}}]},{"cell_type":"code","source":"def process_in_chunks(df, chunk_size, func):\n    num_chunks = int(np.ceil(len(df) / chunk_size))\n    results = []\n    \n    for i in range(num_chunks):\n        start = i * chunk_size\n        end = min((i + 1) * chunk_size, len(df))\n        chunk = df.iloc[start:end].copy()\n        chunk['embs'] = chunk['path'].apply(func)\n        results.append(chunk)\n        \n    return pd.concat(results)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T23:05:43.779488Z","iopub.execute_input":"2024-05-17T23:05:43.779858Z","iopub.status.idle":"2024-05-17T23:05:43.786655Z","shell.execute_reply.started":"2024-05-17T23:05:43.779831Z","shell.execute_reply":"2024-05-17T23:05:43.785730Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"chunk_size = 10","metadata":{"execution":{"iopub.status.busy":"2024-05-17T23:05:45.160304Z","iopub.execute_input":"2024-05-17T23:05:45.160674Z","iopub.status.idle":"2024-05-17T23:05:45.165318Z","shell.execute_reply.started":"2024-05-17T23:05:45.160647Z","shell.execute_reply":"2024-05-17T23:05:45.164258Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"import gc\n\ngc.collect()\n\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-05-17T23:05:46.009928Z","iopub.execute_input":"2024-05-17T23:05:46.011094Z","iopub.status.idle":"2024-05-17T23:05:46.348632Z","shell.execute_reply.started":"2024-05-17T23:05:46.011042Z","shell.execute_reply":"2024-05-17T23:05:46.347469Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"df_train_processed = process_in_chunks(df_train, chunk_size, getFeatures)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T23:05:48.571118Z","iopub.execute_input":"2024-05-17T23:05:48.572118Z","iopub.status.idle":"2024-05-17T23:06:08.159066Z","shell.execute_reply.started":"2024-05-17T23:05:48.572084Z","shell.execute_reply":"2024-05-17T23:06:08.157271Z"},"trusted":true},"execution_count":29,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_train_processed \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_in_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgetFeatures\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[26], line 11\u001b[0m, in \u001b[0;36mprocess_in_chunks\u001b[0;34m(df, chunk_size, func)\u001b[0m\n\u001b[1;32m      9\u001b[0m     end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m((i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m chunk_size, \u001b[38;5;28mlen\u001b[39m(df))\n\u001b[1;32m     10\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[start:end]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 11\u001b[0m     chunk[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membs\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mchunk\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(chunk)\n\u001b[1;32m     13\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n","File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n","Cell \u001b[0;32mIn[17], line 14\u001b[0m, in \u001b[0;36mgetFeatures\u001b[0;34m(video_path)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     container = av.open(video_path)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#     indices = sample_frame_indices(clip_len=8, frame_sample_rate=1, seg_len=container.streams.video[0].frames)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#     video = read_video_pyav(container, indices)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m processor(videos\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(video), return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m     video_features \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_video_features\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m video_features\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/x_clip/modeling_x_clip.py:1431\u001b[0m, in \u001b[0;36mXCLIPModel.get_video_features\u001b[0;34m(self, pixel_values, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1428\u001b[0m batch_size, num_frames, num_channels, height, width \u001b[38;5;241m=\u001b[39m pixel_values\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   1429\u001b[0m pixel_values \u001b[38;5;241m=\u001b[39m pixel_values\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, num_channels, height, width)\n\u001b[0;32m-> 1431\u001b[0m vision_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvision_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpixel_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1433\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1434\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1435\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1438\u001b[0m video_embeds \u001b[38;5;241m=\u001b[39m vision_outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1439\u001b[0m video_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisual_projection(video_embeds)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/x_clip/modeling_x_clip.py:978\u001b[0m, in \u001b[0;36mXCLIPVisionTransformer.forward\u001b[0;34m(self, pixel_values, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    975\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(pixel_values)\n\u001b[1;32m    976\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_layernorm(hidden_states)\n\u001b[0;32m--> 978\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    985\u001b[0m last_hidden_state \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    986\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m last_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/x_clip/modeling_x_clip.py:919\u001b[0m, in \u001b[0;36mXCLIPVisionEncoder.forward\u001b[0;34m(self, inputs_embeds, attention_mask, causal_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    911\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    912\u001b[0m         encoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    913\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    916\u001b[0m         output_attentions,\n\u001b[1;32m    917\u001b[0m     )\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 919\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mencoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcausal_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    926\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/x_clip/modeling_x_clip.py:453\u001b[0m, in \u001b[0;36mXCLIPVisionEncoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, causal_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    451\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    452\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm2(hidden_states)\n\u001b[0;32m--> 453\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    454\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    456\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/x_clip/modeling_x_clip.py:292\u001b[0m, in \u001b[0;36mXCLIPMLP.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    291\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(hidden_states)\n\u001b[0;32m--> 292\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(hidden_states)\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/activations.py:96\u001b[0m, in \u001b[0;36mQuickGELUActivation.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1.702\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 17.06 MiB is free. Process 4701 has 14.73 GiB memory in use. Of the allocated memory 14.06 GiB is allocated by PyTorch, and 546.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 17.06 MiB is free. Process 4701 has 14.73 GiB memory in use. Of the allocated memory 14.06 GiB is allocated by PyTorch, and 546.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error"}]},{"cell_type":"code","source":"df_val_processed = process_in_chunks(df_val, chunk_size, getFeatures)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T22:52:13.051557Z","iopub.status.idle":"2024-05-17T22:52:13.052621Z","shell.execute_reply.started":"2024-05-17T22:52:13.052362Z","shell.execute_reply":"2024-05-17T22:52:13.052383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from catboost import CatBoostClassifier","metadata":{"execution":{"iopub.status.busy":"2024-05-17T22:52:13.053950Z","iopub.status.idle":"2024-05-17T22:52:13.054445Z","shell.execute_reply.started":"2024-05-17T22:52:13.054198Z","shell.execute_reply":"2024-05-17T22:52:13.054218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CatBoostModel_emb = CatBoostClassifier(\n    iterations=1000,\n    learning_rate=0.03,\n    depth=5,\n    use_best_model=True,\n    loss_function='MultiClass',\n    eval_metric='F1:use_weights=False',\n    custom_metric='F1:use_weights=False',\n    random_seed=42,\n    embedding_features=['embs']\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T22:52:13.057989Z","iopub.status.idle":"2024-05-17T22:52:13.059024Z","shell.execute_reply.started":"2024-05-17T22:52:13.058732Z","shell.execute_reply":"2024-05-17T22:52:13.058753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CatBoostModel_emb.fit(\n    df_train_processed['embs'], df_train_processed['Segment_num'],\n    eval_set=(df_val_processed['embs'], df_val_processed['Segment_num']),\n    plot=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T22:52:13.060308Z","iopub.status.idle":"2024-05-17T22:52:13.060765Z","shell.execute_reply.started":"2024-05-17T22:52:13.060530Z","shell.execute_reply":"2024-05-17T22:52:13.060550Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CatBoostModel_emb.get_best_score()","metadata":{"execution":{"iopub.status.busy":"2024-05-17T22:52:13.062679Z","iopub.status.idle":"2024-05-17T22:52:13.063203Z","shell.execute_reply.started":"2024-05-17T22:52:13.062919Z","shell.execute_reply":"2024-05-17T22:52:13.062940Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test_processed = process_in_chunks(df_test, chunk_size, getFeatures)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T22:52:13.064112Z","iopub.status.idle":"2024-05-17T22:52:13.064598Z","shell.execute_reply.started":"2024-05-17T22:52:13.064353Z","shell.execute_reply":"2024-05-17T22:52:13.064372Z"},"trusted":true},"execution_count":null,"outputs":[]}]}