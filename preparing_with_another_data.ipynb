{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8392701,"sourceType":"datasetVersion","datasetId":4992506}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-05-15T11:46:54.213245Z","iopub.execute_input":"2024-05-15T11:46:54.213746Z","iopub.status.idle":"2024-05-15T11:46:54.218415Z","shell.execute_reply.started":"2024-05-15T11:46:54.213715Z","shell.execute_reply":"2024-05-15T11:46:54.217340Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/youtube-video-ads/all_videos_topics.csv').drop(columns='Unnamed: 0')\ndf['link'] = '/kaggle/input/youtube-video-ads/data/' + df['class'] + '/' + df['link'] + '_' + df['class'] + '.mp4'\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-15T11:46:54.219494Z","iopub.execute_input":"2024-05-15T11:46:54.219786Z","iopub.status.idle":"2024-05-15T11:46:54.276611Z","shell.execute_reply.started":"2024-05-15T11:46:54.219762Z","shell.execute_reply":"2024-05-15T11:46:54.275680Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                                link    class\n0  /kaggle/input/youtube-video-ads/data/Alcohol/1...  Alcohol\n1  /kaggle/input/youtube-video-ads/data/Alcohol/2...  Alcohol\n2  /kaggle/input/youtube-video-ads/data/Alcohol/2...  Alcohol\n3  /kaggle/input/youtube-video-ads/data/Alcohol/3...  Alcohol\n4  /kaggle/input/youtube-video-ads/data/Alcohol/4...  Alcohol","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>link</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/youtube-video-ads/data/Alcohol/1...</td>\n      <td>Alcohol</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/youtube-video-ads/data/Alcohol/2...</td>\n      <td>Alcohol</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/youtube-video-ads/data/Alcohol/2...</td>\n      <td>Alcohol</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/youtube-video-ads/data/Alcohol/3...</td>\n      <td>Alcohol</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/youtube-video-ads/data/Alcohol/4...</td>\n      <td>Alcohol</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"! pip install av","metadata":{"execution":{"iopub.status.busy":"2024-05-15T11:46:54.634556Z","iopub.execute_input":"2024-05-15T11:46:54.634941Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Collecting av\n  Downloading av-12.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\nDownloading av-12.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}]},{"cell_type":"code","source":"import av\nimport torch\nimport numpy as np\n\nfrom transformers import AutoProcessor, AutoModel\n\nnp.random.seed(0)\n\n\ndef read_video_pyav(container, indices):\n    frames = []\n    container.seek(0)\n    start_index = indices[0]\n    end_index = indices[-1]\n    for i, frame in enumerate(container.decode(video=0)):\n        if i > end_index:\n            break\n        if i >= start_index and i in indices:\n            frames.append(frame)\n    return np.stack([x.to_ndarray(format=\"rgb24\") for x in frames])\n\n\ndef sample_frame_indices(clip_len, frame_sample_rate, seg_len):\n    converted_len = int(clip_len * frame_sample_rate)\n    end_idx = np.random.randint(converted_len, seg_len)\n    start_idx = end_idx - converted_len\n    indices = np.linspace(start_idx, end_idx, num=clip_len)\n    indices = np.clip(indices, start_idx, end_idx - 1).astype(np.int64)\n    return indices\n\n\nfile_path = '/kaggle/input/youtube-video-ads/data/Alcohol/2S2VUCdbhg0_Alcohol.mp4'\ncontainer = av.open(file_path)\n\nindices = sample_frame_indices(clip_len=8, frame_sample_rate=1, seg_len=container.streams.video[0].frames)\nvideo = read_video_pyav(container, indices)\n\nprocessor = AutoProcessor.from_pretrained(\"microsoft/xclip-base-patch32\")\nmodel = AutoModel.from_pretrained(\"microsoft/xclip-base-patch32\")\n\ninputs = processor(videos=list(video), return_tensors=\"pt\")\n\nvideo_features = model.get_video_features(**inputs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"video_features # можно построить для всех видосов и учиться на этом, пока лень","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cats = ['Alcohol',\n 'Charities',\n 'animal_right',\n 'baby',\n 'beauty',\n 'cars',\n 'chips',\n 'chocolate',\n 'cleaning',\n 'clothing',\n 'coffee',\n 'domestic_violence',\n 'education',\n 'electronics',\n 'environment',\n 'financial',\n 'gambling',\n 'game',\n 'healthcare',\n 'home_appliance',\n 'home_improvement',\n 'human_right',\n 'media',\n 'other_service',\n 'petfood',\n 'phone_tv_internet_providers',\n 'political',\n 'restaurant',\n 'safety',\n 'seasoning',\n 'security',\n 'self_esteem',\n 'shopping',\n 'smoking_alcohol_abuse',\n 'soda',\n 'software',\n 'sports',\n 'travel']","metadata":{"execution":{"iopub.status.busy":"2024-05-15T11:47:26.303295Z","iopub.execute_input":"2024-05-15T11:47:26.303666Z","iopub.status.idle":"2024-05-15T11:47:26.310051Z","shell.execute_reply.started":"2024-05-15T11:47:26.303632Z","shell.execute_reply":"2024-05-15T11:47:26.309021Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import av\nimport torch\nimport numpy as np\n\nfrom transformers import AutoProcessor, AutoModel\n\nnp.random.seed(0)\n\n\ndef read_video_pyav(container, indices):\n    frames = []\n    container.seek(0)\n    start_index = indices[0]\n    end_index = indices[-1]\n    for i, frame in enumerate(container.decode(video=0)):\n        if i > end_index:\n            break\n        if i >= start_index and i in indices:\n            frames.append(frame)\n    return np.stack([x.to_ndarray(format=\"rgb24\") for x in frames])\n\n\ndef sample_frame_indices(clip_len, frame_sample_rate, seg_len):\n    converted_len = int(clip_len * frame_sample_rate)\n    end_idx = np.random.randint(converted_len, seg_len)\n    start_idx = end_idx - converted_len\n    indices = np.linspace(start_idx, end_idx, num=clip_len)\n    indices = np.clip(indices, start_idx, end_idx - 1).astype(np.int64)\n    return indices\n\n\nfile_path = '/kaggle/input/youtube-video-ads/data/domestic_violence/RzDr18UYO18_domestic_violence.mp4'\ncontainer = av.open(file_path)\n\nindices = sample_frame_indices(clip_len=8, frame_sample_rate=1, seg_len=container.streams.video[0].frames)\nvideo = read_video_pyav(container, indices)\n\nprocessor = AutoProcessor.from_pretrained(\"microsoft/xclip-large-patch14\") # microsoft/xclip-base-patch32 будет значительно быстрее, но хуже\nmodel = AutoModel.from_pretrained(\"microsoft/xclip-large-patch14\")\n\ninputs = processor(\n    text=cats,\n    videos=list(video),\n    return_tensors=\"pt\",\n    padding=True,\n)\n\nwith torch.no_grad():\n    outputs = model(**inputs)\n\nlogits_per_video = outputs.logits_per_video\nprobs = logits_per_video.softmax(dim=1)\nprint(probs)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T11:24:33.175189Z","iopub.execute_input":"2024-05-13T11:24:33.175794Z","iopub.status.idle":"2024-05-13T11:25:14.672828Z","shell.execute_reply.started":"2024-05-13T11:24:33.175767Z","shell.execute_reply":"2024-05-13T11:25:14.672043Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/310 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b19d6e74e8345af88f4db53ee02a176"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/927 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f5d651980db45a58e92759e98d26155"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b7bd752c14f4cb5bd1b109d6213bdc1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a7afdca5155426e8547b42330d3bb90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.22M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"001d00adeaf34ee4bd16eb10e74b4f79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bb6d6fa840f4e4182aa1ee4707e150b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/8.90k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecbef6255cf3442589985995cdd0606b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.30G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"613fdd6ed471474b891fe13e14c04bc7"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nUnused or unrecognized kwargs: padding.\n","output_type":"stream"},{"name":"stdout","text":"tensor([[4.5602e-03, 4.7356e-03, 1.5340e-03, 4.8192e-03, 9.3617e-03, 9.5480e-04,\n         7.3969e-03, 3.5365e-04, 4.7143e-03, 4.3138e-04, 3.2520e-04, 9.0296e-01,\n         4.7496e-03, 1.7981e-04, 5.2141e-04, 1.5915e-03, 6.2292e-03, 8.0079e-04,\n         5.4279e-04, 1.0193e-03, 1.5927e-03, 3.4510e-04, 1.6978e-04, 9.3953e-04,\n         1.4380e-03, 1.1267e-03, 1.2318e-03, 5.5164e-04, 1.6341e-02, 1.5449e-03,\n         8.6232e-03, 1.7883e-03, 1.7721e-04, 3.4561e-03, 3.0385e-04, 9.1593e-04,\n         1.2136e-03, 4.6363e-04]])\n","output_type":"stream"}]},{"cell_type":"code","source":"cats[int(np.argmax(probs))] # в целом хорошо работает из коробки, но нужно меньше классов, на таком количестве посос","metadata":{"execution":{"iopub.status.busy":"2024-05-13T11:25:14.674107Z","iopub.execute_input":"2024-05-13T11:25:14.674718Z","iopub.status.idle":"2024-05-13T11:25:14.693329Z","shell.execute_reply.started":"2024-05-13T11:25:14.674687Z","shell.execute_reply":"2024-05-13T11:25:14.692423Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'domestic_violence'"},"metadata":{}}]},{"cell_type":"code","source":"dct = {x: 0 for x in cats}\n\nfor i in range(len(cats)):\n    dct[cats[i]] = float(probs[0][i])","metadata":{"execution":{"iopub.status.busy":"2024-05-13T11:25:14.694784Z","iopub.execute_input":"2024-05-13T11:25:14.695161Z","iopub.status.idle":"2024-05-13T11:25:16.548471Z","shell.execute_reply.started":"2024-05-13T11:25:14.695120Z","shell.execute_reply":"2024-05-13T11:25:16.547184Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"dct","metadata":{"execution":{"iopub.status.busy":"2024-05-13T11:25:16.552929Z","iopub.execute_input":"2024-05-13T11:25:16.553252Z","iopub.status.idle":"2024-05-13T11:25:16.637431Z","shell.execute_reply.started":"2024-05-13T11:25:16.553225Z","shell.execute_reply":"2024-05-13T11:25:16.636434Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'Alcohol': 0.0045602088794112206,\n 'Charities': 0.004735603928565979,\n 'animal_right': 0.001533995382487774,\n 'baby': 0.0048192329704761505,\n 'beauty': 0.009361662901937962,\n 'cars': 0.00095479900483042,\n 'chips': 0.00739690475165844,\n 'chocolate': 0.0003536523145157844,\n 'cleaning': 0.004714334849268198,\n 'clothing': 0.0004313796234782785,\n 'coffee': 0.00032519601518288255,\n 'domestic_violence': 0.902955949306488,\n 'education': 0.004749556537717581,\n 'electronics': 0.00017981327255256474,\n 'environment': 0.0005214101984165609,\n 'financial': 0.001591507694683969,\n 'gambling': 0.006229192018508911,\n 'game': 0.0008007889846339822,\n 'healthcare': 0.0005427923169918358,\n 'home_appliance': 0.0010192592162638903,\n 'home_improvement': 0.0015927336644381285,\n 'human_right': 0.00034509843681007624,\n 'media': 0.00016978185158222914,\n 'other_service': 0.0009395282831974328,\n 'petfood': 0.0014379883650690317,\n 'phone_tv_internet_providers': 0.001126699848100543,\n 'political': 0.0012317555956542492,\n 'restaurant': 0.0005516437813639641,\n 'safety': 0.01634087786078453,\n 'seasoning': 0.0015449204947799444,\n 'security': 0.008623233065009117,\n 'self_esteem': 0.0017882755491882563,\n 'shopping': 0.00017720709729474038,\n 'smoking_alcohol_abuse': 0.003456137143075466,\n 'soda': 0.0003038457944057882,\n 'software': 0.0009159341570921242,\n 'sports': 0.0012135602300986648,\n 'travel': 0.00046363219735212624}"},"metadata":{}}]},{"cell_type":"code","source":"! git clone https://github.com/PKU-YuanGroup/Video-LLaVA","metadata":{"execution":{"iopub.status.busy":"2024-05-15T11:47:30.740837Z","iopub.execute_input":"2024-05-15T11:47:30.741634Z","iopub.status.idle":"2024-05-15T11:47:35.122875Z","shell.execute_reply.started":"2024-05-15T11:47:30.741603Z","shell.execute_reply":"2024-05-15T11:47:35.121784Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Cloning into 'Video-LLaVA'...\nremote: Enumerating objects: 951, done.\u001b[K\nremote: Counting objects: 100% (464/464), done.\u001b[K\nremote: Compressing objects: 100% (186/186), done.\u001b[K\nremote: Total 951 (delta 379), reused 278 (delta 278), pack-reused 487\u001b[K\nReceiving objects: 100% (951/951), 115.32 MiB | 55.44 MiB/s, done.\nResolving deltas: 100% (519/519), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"cd Video-LLaVA","metadata":{"execution":{"iopub.status.busy":"2024-05-15T11:47:35.124976Z","iopub.execute_input":"2024-05-15T11:47:35.125273Z","iopub.status.idle":"2024-05-15T11:47:35.131390Z","shell.execute_reply.started":"2024-05-15T11:47:35.125244Z","shell.execute_reply":"2024-05-15T11:47:35.130520Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/working/Video-LLaVA\n","output_type":"stream"}]},{"cell_type":"code","source":"! ls","metadata":{"execution":{"iopub.status.busy":"2024-05-15T11:47:35.132840Z","iopub.execute_input":"2024-05-15T11:47:35.133278Z","iopub.status.idle":"2024-05-15T11:47:36.088073Z","shell.execute_reply.started":"2024-05-15T11:47:35.133246Z","shell.execute_reply":"2024-05-15T11:47:36.086905Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"LICENSE    TRAIN_AND_VALIDATE.md  pyproject.toml  videollava\nREADME.md  assets\t\t  scripts\n","output_type":"stream"}]},{"cell_type":"code","source":"! pip install --upgrade pip\n! pip install -e .\n! pip install -e \".[train]\"","metadata":{"execution":{"iopub.status.busy":"2024-05-15T11:47:36.091238Z","iopub.execute_input":"2024-05-15T11:47:36.092021Z","iopub.status.idle":"2024-05-15T11:51:54.736898Z","shell.execute_reply.started":"2024-05-15T11:47:36.091979Z","shell.execute_reply":"2024-05-15T11:51:54.735922Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (23.3.2)\nCollecting pip\n  Downloading pip-24.0-py3-none-any.whl.metadata (3.6 kB)\nDownloading pip-24.0-py3-none-any.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 23.3.2\n    Uninstalling pip-23.3.2:\n      Successfully uninstalled pip-23.3.2\nSuccessfully installed pip-24.0\nObtaining file:///kaggle/working/Video-LLaVA\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting torch==2.0.1 (from videollava==1.0.0)\n  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\nCollecting torchvision==0.15.2 (from videollava==1.0.0)\n  Downloading torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl.metadata (11 kB)\nCollecting transformers==4.31.0 (from videollava==1.0.0)\n  Downloading transformers-4.31.0-py3-none-any.whl.metadata (116 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting tokenizers<0.14,>=0.12.1 (from videollava==1.0.0)\n  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nCollecting sentencepiece==0.1.99 (from videollava==1.0.0)\n  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\nCollecting shortuuid (from videollava==1.0.0)\n  Downloading shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\nCollecting accelerate==0.21.0 (from videollava==1.0.0)\n  Downloading accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)\nCollecting peft==0.4.0 (from videollava==1.0.0)\n  Downloading peft-0.4.0-py3-none-any.whl.metadata (21 kB)\nCollecting bitsandbytes==0.41.0 (from videollava==1.0.0)\n  Downloading bitsandbytes-0.41.0-py3-none-any.whl.metadata (9.8 kB)\nCollecting pydantic<2,>=1 (from videollava==1.0.0)\n  Downloading pydantic-1.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (150 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.6/150.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting markdown2[all] (from videollava==1.0.0)\n  Downloading markdown2-2.4.13-py2.py3-none-any.whl.metadata (2.0 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from videollava==1.0.0) (1.26.4)\nRequirement already satisfied: scikit-learn==1.2.2 in /opt/conda/lib/python3.10/site-packages (from videollava==1.0.0) (1.2.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from videollava==1.0.0) (2.31.0)\nCollecting httpx==0.24.0 (from videollava==1.0.0)\n  Downloading httpx-0.24.0-py3-none-any.whl.metadata (8.1 kB)\nRequirement already satisfied: uvicorn in /opt/conda/lib/python3.10/site-packages (from videollava==1.0.0) (0.25.0)\nRequirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from videollava==1.0.0) (0.108.0)\nCollecting einops==0.6.1 (from videollava==1.0.0)\n  Downloading einops-0.6.1-py3-none-any.whl.metadata (12 kB)\nCollecting einops-exts==0.0.4 (from videollava==1.0.0)\n  Downloading einops_exts-0.0.4-py3-none-any.whl.metadata (621 bytes)\nCollecting timm==0.6.13 (from videollava==1.0.0)\n  Downloading timm-0.6.13-py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: tensorboardX==2.6.2.2 in /opt/conda/lib/python3.10/site-packages (from videollava==1.0.0) (2.6.2.2)\nCollecting gradio==3.37.0 (from videollava==1.0.0)\n  Downloading gradio-3.37.0-py3-none-any.whl.metadata (17 kB)\nCollecting gradio-client==0.7.0 (from videollava==1.0.0)\n  Downloading gradio_client-0.7.0-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.21.0->videollava==1.0.0) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.21.0->videollava==1.0.0) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.21.0->videollava==1.0.0) (6.0.1)\nRequirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.37.0->videollava==1.0.0) (22.1.0)\nRequirement already satisfied: aiohttp~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.37.0->videollava==1.0.0) (3.9.1)\nRequirement already satisfied: altair<6.0,>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.37.0->videollava==1.0.0) (5.3.0)\nCollecting ffmpy (from gradio==3.37.0->videollava==1.0.0)\n  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: huggingface-hub>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.37.0->videollava==1.0.0) (0.22.2)\nRequirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.37.0->videollava==1.0.0) (3.1.2)\nRequirement already satisfied: markdown-it-py>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.37.0->videollava==1.0.0) (3.0.0)\nRequirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.37.0->videollava==1.0.0) (2.1.3)\nRequirement already satisfied: matplotlib~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.37.0->videollava==1.0.0) (3.7.5)\nCollecting mdit-py-plugins<=0.3.3 (from gradio==3.37.0->videollava==1.0.0)\n  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.37.0->videollava==1.0.0) (3.9.10)\nRequirement already satisfied: pandas<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.37.0->videollava==1.0.0) (2.1.4)\nRequirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.37.0->videollava==1.0.0) (9.5.0)\nRequirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio==3.37.0->videollava==1.0.0) (0.25.1)\nCollecting python-multipart (from gradio==3.37.0->videollava==1.0.0)\n  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\nCollecting semantic-version~=2.0 (from gradio==3.37.0->videollava==1.0.0)\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\nRequirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.37.0->videollava==1.0.0) (4.9.0)\nCollecting websockets<12.0,>=10.0 (from gradio==3.37.0->videollava==1.0.0)\n  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from gradio-client==0.7.0->videollava==1.0.0) (2024.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx==0.24.0->videollava==1.0.0) (2024.2.2)\nCollecting httpcore<0.18.0,>=0.15.0 (from httpx==0.24.0->videollava==1.0.0)\n  Downloading httpcore-0.17.3-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx==0.24.0->videollava==1.0.0) (3.6)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx==0.24.0->videollava==1.0.0) (1.3.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->videollava==1.0.0) (0.4.3)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.2.2->videollava==1.0.0) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.2.2->videollava==1.0.0) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.2.2->videollava==1.0.0) (3.2.0)\nRequirement already satisfied: protobuf>=3.20 in /opt/conda/lib/python3.10/site-packages (from tensorboardX==2.6.2.2->videollava==1.0.0) (3.20.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->videollava==1.0.0) (3.13.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->videollava==1.0.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->videollava==1.0.0) (3.2.1)\nCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1->videollava==1.0.0)\n  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1->videollava==1.0.0)\n  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1->videollava==1.0.0)\n  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1->videollava==1.0.0)\n  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1->videollava==1.0.0)\n  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1->videollava==1.0.0)\n  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1->videollava==1.0.0)\n  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1->videollava==1.0.0)\n  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1->videollava==1.0.0)\n  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1->videollava==1.0.0)\n  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1->videollava==1.0.0)\n  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.0.0 (from torch==2.0.1->videollava==1.0.0)\n  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0->videollava==1.0.0) (2023.12.25)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0->videollava==1.0.0) (4.66.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->videollava==1.0.0) (69.0.3)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->videollava==1.0.0) (0.42.0)\nCollecting cmake (from triton==2.0.0->torch==2.0.1->videollava==1.0.0)\n  Downloading cmake-3.29.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)\nCollecting lit (from triton==2.0.0->torch==2.0.1->videollava==1.0.0)\n  Downloading lit-18.1.4-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->videollava==1.0.0) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->videollava==1.0.0) (1.26.18)\nRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn->videollava==1.0.0) (8.1.7)\nRequirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn->videollava==1.0.0) (0.14.0)\nRequirement already satisfied: starlette<0.33.0,>=0.29.0 in /opt/conda/lib/python3.10/site-packages (from fastapi->videollava==1.0.0) (0.32.0.post1)\nRequirement already satisfied: pygments>=2.7.3 in /opt/conda/lib/python3.10/site-packages (from markdown2[all]->videollava==1.0.0) (2.17.2)\nCollecting wavedrom (from markdown2[all]->videollava==1.0.0)\n  Downloading wavedrom-2.0.3.post3.tar.gz (137 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp~=3.0->gradio==3.37.0->videollava==1.0.0) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp~=3.0->gradio==3.37.0->videollava==1.0.0) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp~=3.0->gradio==3.37.0->videollava==1.0.0) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp~=3.0->gradio==3.37.0->videollava==1.0.0) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp~=3.0->gradio==3.37.0->videollava==1.0.0) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp~=3.0->gradio==3.37.0->videollava==1.0.0) (4.0.3)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio==3.37.0->videollava==1.0.0) (4.20.0)\nRequirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio==3.37.0->videollava==1.0.0) (0.12.1)\nRequirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx==0.24.0->videollava==1.0.0) (4.2.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.0.0->markdown-it-py[linkify]>=2.0.0->gradio==3.37.0->videollava==1.0.0) (0.1.2)\nRequirement already satisfied: linkify-it-py<3,>=1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.37.0->videollava==1.0.0) (2.0.3)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio==3.37.0->videollava==1.0.0) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio==3.37.0->videollava==1.0.0) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio==3.37.0->videollava==1.0.0) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio==3.37.0->videollava==1.0.0) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio==3.37.0->videollava==1.0.0) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio==3.37.0->videollava==1.0.0) (2.9.0.post0)\nINFO: pip is looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\nCollecting mdit-py-plugins<=0.3.3 (from gradio==3.37.0->videollava==1.0.0)\n  Downloading mdit_py_plugins-0.3.2-py3-none-any.whl.metadata (2.8 kB)\n  Downloading mdit_py_plugins-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n  Downloading mdit_py_plugins-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n  Downloading mdit_py_plugins-0.2.8-py3-none-any.whl.metadata (2.8 kB)\n  Downloading mdit_py_plugins-0.2.7-py3-none-any.whl.metadata (2.8 kB)\n  Downloading mdit_py_plugins-0.2.6-py3-none-any.whl.metadata (2.6 kB)\n  Downloading mdit_py_plugins-0.2.5-py3-none-any.whl.metadata (2.6 kB)\nINFO: pip is still looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n  Downloading mdit_py_plugins-0.2.4-py3-none-any.whl.metadata (2.6 kB)\n  Downloading mdit_py_plugins-0.2.3-py3-none-any.whl.metadata (2.6 kB)\n  Downloading mdit_py_plugins-0.2.2-py3-none-any.whl.metadata (2.6 kB)\n  Downloading mdit_py_plugins-0.2.1-py3-none-any.whl.metadata (2.6 kB)\n  Downloading mdit_py_plugins-0.2.0-py3-none-any.whl.metadata (2.6 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Downloading mdit_py_plugins-0.1.0-py3-none-any.whl.metadata (2.6 kB)\nCollecting markdown-it-py[linkify]>=2.0.0 (from gradio==3.37.0->videollava==1.0.0)\n  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n  Downloading markdown_it_py-2.2.0-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio==3.37.0->videollava==1.0.0) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio==3.37.0->videollava==1.0.0) (2023.4)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.0.1->videollava==1.0.0) (1.3.0)\nCollecting svgwrite (from wavedrom->markdown2[all]->videollava==1.0.0)\n  Downloading svgwrite-1.4.3-py3-none-any.whl.metadata (8.8 kB)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from wavedrom->markdown2[all]->videollava==1.0.0) (1.16.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx==0.24.0->videollava==1.0.0) (1.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.37.0->videollava==1.0.0) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.37.0->videollava==1.0.0) (0.32.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.37.0->videollava==1.0.0) (0.16.2)\nRequirement already satisfied: uc-micro-py in /opt/conda/lib/python3.10/site-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio==3.37.0->videollava==1.0.0) (1.0.3)\nDownloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.41.0-py3-none-any.whl (92.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading einops-0.6.1-py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading einops_exts-0.0.4-py3-none-any.whl (3.9 kB)\nDownloading gradio-3.37.0-py3-none-any.whl (19.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gradio_client-0.7.0-py3-none-any.whl (302 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.7/302.7 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpx-0.24.0-py3-none-any.whl (75 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.3/75.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading peft-0.4.0-py3-none-any.whl (72 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading timm-0.6.13-py3-none-any.whl (549 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m593.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pydantic-1.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\nDownloading httpcore-0.17.3-py3-none-any.whl (74 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nDownloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading markdown2-2.4.13-py2.py3-none-any.whl (41 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\nDownloading cmake-3.29.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading lit-18.1.4-py3-none-any.whl (96 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: videollava, ffmpy, wavedrom\n  Building editable for videollava (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for videollava: filename=videollava-1.0.0-0.editable-py3-none-any.whl size=12742 sha256=e088d5154d335d785023b3df4620328d785115b42651354bb84daf88cc3074d4\n  Stored in directory: /tmp/pip-ephem-wheel-cache-14h9d3p9/wheels/3c/e3/3e/9b9e9de50473eebf19d7ffe399d999c2706b5e7c022f75073f\n  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=63afaf92a21ddf9e4f64ca92f61d422f4c5e82ced00968009781c221d66c8b8f\n  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n  Building wheel for wavedrom (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for wavedrom: filename=wavedrom-2.0.3.post3-py2.py3-none-any.whl size=30052 sha256=3934e464b76d4b4378ea0e6ac75a37f52a34cf3468eb4213895cf41d640153cc\n  Stored in directory: /root/.cache/pip/wheels/9c/52/8c/38b454b42f712f325e26f633287484c7dc1ad469e1580c5954\nSuccessfully built videollava ffmpy wavedrom\nInstalling collected packages: tokenizers, sentencepiece, lit, ffmpy, bitsandbytes, websockets, svgwrite, shortuuid, semantic-version, python-multipart, pydantic, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, markdown2, markdown-it-py, einops, cmake, wavedrom, nvidia-cusolver-cu11, nvidia-cudnn-cu11, mdit-py-plugins, httpcore, einops-exts, transformers, httpx, gradio-client, gradio, triton, torch, torchvision, accelerate, timm, peft, videollava\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.15.2\n    Uninstalling tokenizers-0.15.2:\n      Successfully uninstalled tokenizers-0.15.2\n  Attempting uninstall: sentencepiece\n    Found existing installation: sentencepiece 0.2.0\n    Uninstalling sentencepiece-0.2.0:\n      Successfully uninstalled sentencepiece-0.2.0\n  Attempting uninstall: websockets\n    Found existing installation: websockets 12.0\n    Uninstalling websockets-12.0:\n      Successfully uninstalled websockets-12.0\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 2.5.3\n    Uninstalling pydantic-2.5.3:\n      Successfully uninstalled pydantic-2.5.3\n  Attempting uninstall: markdown-it-py\n    Found existing installation: markdown-it-py 3.0.0\n    Uninstalling markdown-it-py-3.0.0:\n      Successfully uninstalled markdown-it-py-3.0.0\n  Attempting uninstall: mdit-py-plugins\n    Found existing installation: mdit-py-plugins 0.4.0\n    Uninstalling mdit-py-plugins-0.4.0:\n      Successfully uninstalled mdit-py-plugins-0.4.0\n  Attempting uninstall: httpcore\n    Found existing installation: httpcore 1.0.5\n    Uninstalling httpcore-1.0.5:\n      Successfully uninstalled httpcore-1.0.5\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.39.3\n    Uninstalling transformers-4.39.3:\n      Successfully uninstalled transformers-4.39.3\n  Attempting uninstall: httpx\n    Found existing installation: httpx 0.27.0\n    Uninstalling httpx-0.27.0:\n      Successfully uninstalled httpx-0.27.0\n  Attempting uninstall: torch\n    Found existing installation: torch 2.1.2\n    Uninstalling torch-2.1.2:\n      Successfully uninstalled torch-2.1.2\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.16.2\n    Uninstalling torchvision-0.16.2:\n      Successfully uninstalled torchvision-0.16.2\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.29.3\n    Uninstalling accelerate-0.29.3:\n      Successfully uninstalled accelerate-0.29.3\n  Attempting uninstall: timm\n    Found existing installation: timm 0.9.16\n    Uninstalling timm-0.9.16:\n      Successfully uninstalled timm-0.9.16\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\njupyterlab 4.1.6 requires httpx>=0.25.0, but you have httpx 0.24.0 which is incompatible.\njupyterlab 4.1.6 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nkaggle-environments 1.14.3 requires transformers>=4.33.1, but you have transformers 4.31.0 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\nydata-profiling 4.6.4 requires pydantic>=2, but you have pydantic 1.10.15 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed accelerate-0.21.0 bitsandbytes-0.41.0 cmake-3.29.3 einops-0.6.1 einops-exts-0.0.4 ffmpy-0.3.2 gradio-3.37.0 gradio-client-0.7.0 httpcore-0.17.3 httpx-0.24.0 lit-18.1.4 markdown-it-py-2.2.0 markdown2-2.4.13 mdit-py-plugins-0.3.3 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 peft-0.4.0 pydantic-1.10.15 python-multipart-0.0.9 semantic-version-2.10.0 sentencepiece-0.1.99 shortuuid-1.0.13 svgwrite-1.4.3 timm-0.6.13 tokenizers-0.13.3 torch-2.0.1 torchvision-0.15.2 transformers-4.31.0 triton-2.0.0 videollava-1.0.0 wavedrom-2.0.3.post3 websockets-11.0.3\nObtaining file:///kaggle/working/Video-LLaVA\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch==2.0.1 in /opt/conda/lib/python3.10/site-packages (from videollava==1.0.0) (2.0.1)\nRequirement already satisfied: torchvision==0.15.2 in /opt/conda/lib/python3.10/site-packages (from videollava==1.0.0) (0.15.2)\nRequirement already satisfied: transformers==4.31.0 in /opt/conda/lib/python3.10/site-packages (from videollava==1.0.0) (4.31.0)\nRequirement already satisfied: tokenizers<0.14,>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from videollava==1.0.0) (0.13.3)\nRequirement already satisfied: sentencepiece==0.1.99 in /opt/conda/lib/python3.10/site-packages (from videollava==1.0.0) (0.1.99)\nRequirement already satisfied: shortuuid in /opt/conda/lib/python3.10/site-packages (from videollava==1.0.0) (1.0.13)\nRequirement already satisfied: accelerate==0.21.0 in /opt/conda/lib/python3.10/site-packages (from videollava==1.0.0) (0.21.0)\nRequirement already satisfied: peft==0.4.0 in /opt/conda/lib/python3.10/site-packages (from videollava==1.0.0) (0.4.0)\nRequirement already satisfied: bitsandbytes==0.41.0 in /opt/conda/lib/python3.10/site-packages (from videollava==1.0.0) (0.41.0)\nRequirement already satisfied: pydantic<2,>=1 in /opt/conda/lib/python3.10/site-packages (from videollava==1.0.0) (1.10.15)\nRequirement already satisfied: markdown2[all] in /opt/conda/lib/python3.10/site-packages (from videollava==1.0.0) (2.4.13)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from videollava==1.0.0) (1.26.4)\nRequirement already satisfied: scikit-learn==1.2.2 in /opt/conda/lib/python3.10/site-packages (from videollava==1.0.0) (1.2.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from videollava==1.0.0) (2.31.0)\nRequirement already satisfied: httpx==0.24.0 in /opt/conda/lib/python3.10/site-packages (from videollava==1.0.0) (0.24.0)\nRequirement already satisfied: uvicorn in /opt/conda/lib/python3.10/site-packages (from videollava==1.0.0) (0.25.0)\nRequirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from videollava==1.0.0) (0.108.0)\nRequirement already satisfied: einops==0.6.1 in /opt/conda/lib/python3.10/site-packages (from videollava==1.0.0) (0.6.1)\nRequirement already satisfied: einops-exts==0.0.4 in /opt/conda/lib/python3.10/site-packages (from videollava==1.0.0) (0.0.4)\nRequirement already satisfied: timm==0.6.13 in /opt/conda/lib/python3.10/site-packages (from videollava==1.0.0) (0.6.13)\nRequirement already satisfied: tensorboardX==2.6.2.2 in /opt/conda/lib/python3.10/site-packages (from videollava==1.0.0) (2.6.2.2)\nRequirement already satisfied: gradio==3.37.0 in /opt/conda/lib/python3.10/site-packages (from videollava==1.0.0) (3.37.0)\nRequirement already satisfied: gradio-client==0.7.0 in /opt/conda/lib/python3.10/site-packages (from videollava==1.0.0) (0.7.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.21.0->videollava==1.0.0) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.21.0->videollava==1.0.0) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.21.0->videollava==1.0.0) (6.0.1)\nRequirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.37.0->videollava==1.0.0) (22.1.0)\nRequirement already satisfied: aiohttp~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.37.0->videollava==1.0.0) (3.9.1)\nRequirement already satisfied: altair<6.0,>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.37.0->videollava==1.0.0) (5.3.0)\nRequirement already satisfied: ffmpy in /opt/conda/lib/python3.10/site-packages (from gradio==3.37.0->videollava==1.0.0) (0.3.2)\nRequirement already satisfied: huggingface-hub>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.37.0->videollava==1.0.0) (0.22.2)\nRequirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.37.0->videollava==1.0.0) (3.1.2)\nRequirement already satisfied: markdown-it-py>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.37.0->videollava==1.0.0) (2.2.0)\nRequirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.37.0->videollava==1.0.0) (2.1.3)\nRequirement already satisfied: matplotlib~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.37.0->videollava==1.0.0) (3.7.5)\nRequirement already satisfied: mdit-py-plugins<=0.3.3 in /opt/conda/lib/python3.10/site-packages (from gradio==3.37.0->videollava==1.0.0) (0.3.3)\nRequirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.37.0->videollava==1.0.0) (3.9.10)\nRequirement already satisfied: pandas<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.37.0->videollava==1.0.0) (2.1.4)\nRequirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.37.0->videollava==1.0.0) (9.5.0)\nRequirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio==3.37.0->videollava==1.0.0) (0.25.1)\nRequirement already satisfied: python-multipart in /opt/conda/lib/python3.10/site-packages (from gradio==3.37.0->videollava==1.0.0) (0.0.9)\nRequirement already satisfied: semantic-version~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.37.0->videollava==1.0.0) (2.10.0)\nRequirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.37.0->videollava==1.0.0) (4.9.0)\nRequirement already satisfied: websockets<12.0,>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.37.0->videollava==1.0.0) (11.0.3)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from gradio-client==0.7.0->videollava==1.0.0) (2024.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx==0.24.0->videollava==1.0.0) (2024.2.2)\nRequirement already satisfied: httpcore<0.18.0,>=0.15.0 in /opt/conda/lib/python3.10/site-packages (from httpx==0.24.0->videollava==1.0.0) (0.17.3)\nRequirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx==0.24.0->videollava==1.0.0) (3.6)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx==0.24.0->videollava==1.0.0) (1.3.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0->videollava==1.0.0) (0.4.3)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.2.2->videollava==1.0.0) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.2.2->videollava==1.0.0) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.2.2->videollava==1.0.0) (3.2.0)\nRequirement already satisfied: protobuf>=3.20 in /opt/conda/lib/python3.10/site-packages (from tensorboardX==2.6.2.2->videollava==1.0.0) (3.20.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->videollava==1.0.0) (3.13.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->videollava==1.0.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->videollava==1.0.0) (3.2.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->videollava==1.0.0) (11.7.99)\nRequirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->videollava==1.0.0) (11.7.99)\nRequirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->videollava==1.0.0) (11.7.101)\nRequirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->videollava==1.0.0) (8.5.0.96)\nRequirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->videollava==1.0.0) (11.10.3.66)\nRequirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->videollava==1.0.0) (10.9.0.58)\nRequirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->videollava==1.0.0) (10.2.10.91)\nRequirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->videollava==1.0.0) (11.4.0.1)\nRequirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->videollava==1.0.0) (11.7.4.91)\nRequirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->videollava==1.0.0) (2.14.3)\nRequirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->videollava==1.0.0) (11.7.91)\nRequirement already satisfied: triton==2.0.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1->videollava==1.0.0) (2.0.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0->videollava==1.0.0) (2023.12.25)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0->videollava==1.0.0) (4.66.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->videollava==1.0.0) (69.0.3)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->videollava==1.0.0) (0.42.0)\nRequirement already satisfied: cmake in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.1->videollava==1.0.0) (3.29.3)\nRequirement already satisfied: lit in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.1->videollava==1.0.0) (18.1.4)\nCollecting deepspeed==0.9.5 (from videollava==1.0.0)\n  Downloading deepspeed-0.9.5.tar.gz (809 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.9/809.9 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from videollava==1.0.0) (1.11.1.1)\nRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (from videollava==1.0.0) (0.16.6)\nCollecting hjson (from deepspeed==0.9.5->videollava==1.0.0)\n  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.9.5->videollava==1.0.0) (9.0.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->videollava==1.0.0) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->videollava==1.0.0) (1.26.18)\nRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn->videollava==1.0.0) (8.1.7)\nRequirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn->videollava==1.0.0) (0.14.0)\nRequirement already satisfied: starlette<0.33.0,>=0.29.0 in /opt/conda/lib/python3.10/site-packages (from fastapi->videollava==1.0.0) (0.32.0.post1)\nRequirement already satisfied: pygments>=2.7.3 in /opt/conda/lib/python3.10/site-packages (from markdown2[all]->videollava==1.0.0) (2.17.2)\nRequirement already satisfied: wavedrom in /opt/conda/lib/python3.10/site-packages (from markdown2[all]->videollava==1.0.0) (2.0.3.post3)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->videollava==1.0.0) (3.1.41)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->videollava==1.0.0) (1.45.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb->videollava==1.0.0) (0.4.0)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb->videollava==1.0.0) (1.3.3)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb->videollava==1.0.0) (1.4.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp~=3.0->gradio==3.37.0->videollava==1.0.0) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp~=3.0->gradio==3.37.0->videollava==1.0.0) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp~=3.0->gradio==3.37.0->videollava==1.0.0) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp~=3.0->gradio==3.37.0->videollava==1.0.0) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp~=3.0->gradio==3.37.0->videollava==1.0.0) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp~=3.0->gradio==3.37.0->videollava==1.0.0) (4.0.3)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio==3.37.0->videollava==1.0.0) (4.20.0)\nRequirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio==3.37.0->videollava==1.0.0) (0.12.1)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb->videollava==1.0.0) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb->videollava==1.0.0) (4.0.11)\nRequirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx==0.24.0->videollava==1.0.0) (4.2.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.0.0->markdown-it-py[linkify]>=2.0.0->gradio==3.37.0->videollava==1.0.0) (0.1.2)\nRequirement already satisfied: linkify-it-py<3,>=1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.37.0->videollava==1.0.0) (2.0.3)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio==3.37.0->videollava==1.0.0) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio==3.37.0->videollava==1.0.0) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio==3.37.0->videollava==1.0.0) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio==3.37.0->videollava==1.0.0) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio==3.37.0->videollava==1.0.0) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio==3.37.0->videollava==1.0.0) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio==3.37.0->videollava==1.0.0) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio==3.37.0->videollava==1.0.0) (2023.4)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.0.1->videollava==1.0.0) (1.3.0)\nRequirement already satisfied: svgwrite in /opt/conda/lib/python3.10/site-packages (from wavedrom->markdown2[all]->videollava==1.0.0) (1.4.3)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx==0.24.0->videollava==1.0.0) (1.2.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->videollava==1.0.0) (5.0.1)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.37.0->videollava==1.0.0) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.37.0->videollava==1.0.0) (0.32.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.37.0->videollava==1.0.0) (0.16.2)\nRequirement already satisfied: uc-micro-py in /opt/conda/lib/python3.10/site-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio==3.37.0->videollava==1.0.0) (1.0.3)\nDownloading hjson-3.1.0-py3-none-any.whl (54 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hChecking if build backend supports build_editable ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: videollava, deepspeed\n  Building editable for videollava (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for videollava: filename=videollava-1.0.0-0.editable-py3-none-any.whl size=12742 sha256=005dcd740e0805519b6ab3138553573eb8ef79b019d9fb3bb9514a571c271849\n  Stored in directory: /tmp/pip-ephem-wheel-cache-b567l_tc/wheels/3c/e3/3e/9b9e9de50473eebf19d7ffe399d999c2706b5e7c022f75073f\n  Building wheel for deepspeed (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for deepspeed: filename=deepspeed-0.9.5-py3-none-any.whl size=844527 sha256=5ffed0212a1eb47859d7e1e2e30a920cdd99125275d61d70d34356425de51376\n  Stored in directory: /root/.cache/pip/wheels/7e/a9/bb/a00d383521da14dc91b65ae2d0062401b750d968a548401b2a\nSuccessfully built videollava deepspeed\nInstalling collected packages: hjson, videollava, deepspeed\n  Attempting uninstall: videollava\n    Found existing installation: videollava 1.0.0\n    Uninstalling videollava-1.0.0:\n      Successfully uninstalled videollava-1.0.0\nSuccessfully installed deepspeed-0.9.5 hjson-3.1.0 videollava-1.0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"! pip install flash-attn --no-build-isolation\n! pip install decord opencv-python git+https://github.com/facebookresearch/pytorchvideo.git@28fe037d212663c6a24f373b94cc5d478c8c1a1d","metadata":{"execution":{"iopub.status.busy":"2024-05-15T11:51:54.738425Z","iopub.execute_input":"2024-05-15T11:51:54.738812Z","iopub.status.idle":"2024-05-15T11:52:43.298544Z","shell.execute_reply.started":"2024-05-15T11:51:54.738781Z","shell.execute_reply":"2024-05-15T11:52:43.297456Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Collecting flash-attn\n  Downloading flash_attn-2.5.8.tar.gz (2.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from flash-attn) (2.0.1)\nRequirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from flash-attn) (0.6.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from flash-attn) (21.3)\nRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from flash-attn) (1.11.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->flash-attn) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.1.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (11.7.99)\nRequirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (11.7.99)\nRequirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (11.7.101)\nRequirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (8.5.0.96)\nRequirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (11.10.3.66)\nRequirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (10.9.0.58)\nRequirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (10.2.10.91)\nRequirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (11.4.0.1)\nRequirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (11.7.4.91)\nRequirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (2.14.3)\nRequirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (11.7.91)\nRequirement already satisfied: triton==2.0.0 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (2.0.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->flash-attn) (69.0.3)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->flash-attn) (0.42.0)\nRequirement already satisfied: cmake in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch->flash-attn) (3.29.3)\nRequirement already satisfied: lit in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch->flash-attn) (18.1.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->flash-attn) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->flash-attn) (1.3.0)\nBuilding wheels for collected packages: flash-attn\n  Building wheel for flash-attn (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for flash-attn: filename=flash_attn-2.5.8-cp310-cp310-linux_x86_64.whl size=121687847 sha256=7544f11c6e8f86ed1b737b01bbe4fb1ccfad155dea5ff2d287699d04e6728459\n  Stored in directory: /root/.cache/pip/wheels/9b/5b/2b/dea8af4e954161c49ef1941938afcd91bb93689371ed12a226\nSuccessfully built flash-attn\nInstalling collected packages: flash-attn\nSuccessfully installed flash-attn-2.5.8\nCollecting git+https://github.com/facebookresearch/pytorchvideo.git@28fe037d212663c6a24f373b94cc5d478c8c1a1d\n  Cloning https://github.com/facebookresearch/pytorchvideo.git (to revision 28fe037d212663c6a24f373b94cc5d478c8c1a1d) to /tmp/pip-req-build-bgydfamv\n  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/pytorchvideo.git /tmp/pip-req-build-bgydfamv\n  Running command git rev-parse -q --verify 'sha^28fe037d212663c6a24f373b94cc5d478c8c1a1d'\n  Running command git fetch -q https://github.com/facebookresearch/pytorchvideo.git 28fe037d212663c6a24f373b94cc5d478c8c1a1d\n  Running command git checkout -q 28fe037d212663c6a24f373b94cc5d478c8c1a1d\n  Resolved https://github.com/facebookresearch/pytorchvideo.git to commit 28fe037d212663c6a24f373b94cc5d478c8c1a1d\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting decord\n  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl.metadata (422 bytes)\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (4.9.0.80)\nRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from decord) (1.26.4)\nCollecting fvcore (from pytorchvideo==0.1.5)\n  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting av (from pytorchvideo==0.1.5)\n  Downloading av-12.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\nCollecting parameterized (from pytorchvideo==0.1.5)\n  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\nCollecting iopath (from pytorchvideo==0.1.5)\n  Downloading iopath-0.1.10.tar.gz (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from pytorchvideo==0.1.5) (3.2.1)\nCollecting yacs>=0.1.6 (from fvcore->pytorchvideo==0.1.5)\n  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from fvcore->pytorchvideo==0.1.5) (6.0.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from fvcore->pytorchvideo==0.1.5) (4.66.1)\nRequirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.10/site-packages (from fvcore->pytorchvideo==0.1.5) (2.4.0)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from fvcore->pytorchvideo==0.1.5) (9.5.0)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from fvcore->pytorchvideo==0.1.5) (0.9.0)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.10/site-packages (from iopath->pytorchvideo==0.1.5) (4.9.0)\nCollecting portalocker (from iopath->pytorchvideo==0.1.5)\n  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\nDownloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading av-12.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\nDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\nDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\nBuilding wheels for collected packages: pytorchvideo, fvcore, iopath\n  Building wheel for pytorchvideo (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pytorchvideo: filename=pytorchvideo-0.1.5-py3-none-any.whl size=211199 sha256=f41c9cfe6408eccaa773638475fbdaee15b15815be5d5b5b4e93d4170da13d2e\n  Stored in directory: /root/.cache/pip/wheels/a8/a0/a9/b2f1582cd6198b0425b645bdcce413a15f58d9cc3beee721d0\n  Building wheel for fvcore (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61400 sha256=eb670e1a8fc03fcbcf6719704ef05a791f3b133ba410faf1908c2a36fab63e42\n  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n  Building wheel for iopath (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31532 sha256=fad68bdcefc2d7dae6048d115d11e2b5c4abda473d664a604d26f18e5c517fa2\n  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\nSuccessfully built pytorchvideo fvcore iopath\nInstalling collected packages: yacs, portalocker, parameterized, decord, av, iopath, fvcore, pytorchvideo\nSuccessfully installed av-12.0.0 decord-0.6.0 fvcore-0.1.5.post20221221 iopath-0.1.10 parameterized-0.9.0 portalocker-2.8.2 pytorchvideo-0.1.5 yacs-0.1.8\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import pipeline\n\nfrom videollava.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN\nfrom videollava.conversation import conv_templates, SeparatorStyle\nfrom videollava.model.builder import load_pretrained_model\nfrom videollava.utils import disable_torch_init\nfrom videollava.mm_utils import tokenizer_image_token, get_model_name_from_path, KeywordsStoppingCriteria","metadata":{"execution":{"iopub.status.busy":"2024-05-15T11:52:43.300027Z","iopub.execute_input":"2024-05-15T11:52:43.300352Z","iopub.status.idle":"2024-05-15T11:53:01.357948Z","shell.execute_reply.started":"2024-05-15T11:52:43.300321Z","shell.execute_reply":"2024-05-15T11:53:01.356965Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"2024-05-15 11:52:48.248574: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-15 11:52:48.248674: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-15 11:52:48.390825: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"[2024-05-15 11:52:58,252] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"disable_torch_init() # запускать только один раз","metadata":{"execution":{"iopub.status.busy":"2024-05-15T11:53:01.359157Z","iopub.execute_input":"2024-05-15T11:53:01.359760Z","iopub.status.idle":"2024-05-15T11:53:01.367813Z","shell.execute_reply.started":"2024-05-15T11:53:01.359716Z","shell.execute_reply":"2024-05-15T11:53:01.366957Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model_path = 'LanguageBind/Video-LLaVA-7B'\ncache_dir = 'cache_dir'\ndevice = 'cuda'\n\nload_4bit, load_8bit = True, False\nmodel_name = get_model_name_from_path(model_path)\ntokenizer, model, processor, _ = load_pretrained_model(model_path, \n                                                       None, \n                                                       model_name, \n                                                       load_8bit, \n                                                       load_4bit, \n                                                       device=device, \n                                                       cache_dir=cache_dir)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T11:53:01.368877Z","iopub.execute_input":"2024-05-15T11:53:01.369186Z","iopub.status.idle":"2024-05-15T11:55:23.622084Z","shell.execute_reply.started":"2024-05-15T11:53:01.369161Z","shell.execute_reply":"2024-05-15T11:55:23.620977Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/749 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22ffb258580f47a6b9dfb42aa861834f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"faf0fcb16bb141b0aaecea1d1a53149f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73310289893a4813a40b7d5ef6891c5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.09k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9d8063dc20f49b6bd692bbe317b59f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/150k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b521f52c2f1d473facbf1b74aa9c8403"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd93d180384b43078a5235fa79bd3245"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1e15172860e4eb2a6b0104274bde139"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1decd72fc1d7430db2796409e760548c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/4.61k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a84cd3203d644b1bbd40a4e8d83def23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/4.61k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57907f1f413d45adaa214f2254617cff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4aff7502fd54caf93e904f4e44570bf"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at LanguageBind/Video-LLaVA-7B were not used when initializing LlavaLlamaForCausalLM: ['model.video_tower.video_tower.encoder.layers.12.self_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.5.mlp.fc1.weight', 'model.image_tower.image_tower.encoder.layers.7.layer_norm2.weight', 'model.image_tower.image_tower.encoder.layers.23.self_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.23.mlp.fc1.bias', 'model.image_tower.image_tower.encoder.layers.23.layer_norm2.weight', 'model.video_tower.video_tower.encoder.layers.7.self_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.18.layer_norm2.weight', 'model.video_tower.video_tower.encoder.layers.5.self_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.9.temporal_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.6.self_attn.out_proj.bias', 'model.image_tower.image_tower.encoder.layers.14.mlp.fc1.bias', 'model.image_tower.image_tower.encoder.layers.16.self_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.8.mlp.fc1.weight', 'model.video_tower.video_tower.encoder.layers.19.self_attn.k_proj.weight', 'model.image_tower.image_tower.encoder.layers.23.layer_norm2.bias', 'model.video_tower.video_tower.encoder.layers.5.temporal_attn.k_proj.bias', 'model.image_tower.image_tower.encoder.layers.8.self_attn.k_proj.bias', 'model.image_tower.image_tower.encoder.layers.0.layer_norm1.bias', 'model.image_tower.image_tower.encoder.layers.13.self_attn.v_proj.bias', 'model.image_tower.image_tower.encoder.layers.16.mlp.fc2.weight', 'model.video_tower.video_tower.encoder.layers.8.mlp.fc2.weight', 'model.video_tower.video_tower.encoder.layers.16.temporal_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.3.self_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.11.temporal_attn.q_proj.bias', 'model.image_tower.image_tower.encoder.layers.3.self_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.23.temporal_embedding', 'model.image_tower.image_tower.encoder.layers.17.layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.12.mlp.fc2.bias', 'model.video_tower.video_tower.encoder.layers.6.layer_norm2.weight', 'model.video_tower.video_tower.encoder.layers.14.mlp.fc1.weight', 'model.image_tower.image_tower.encoder.layers.3.layer_norm2.weight', 'model.image_tower.image_tower.encoder.layers.9.self_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.22.self_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.18.layer_norm2.bias', 'model.video_tower.video_tower.encoder.layers.12.temporal_attn.v_proj.weight', 'model.image_tower.image_tower.encoder.layers.2.self_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.11.temporal_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.17.temporal_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.22.mlp.fc1.weight', 'model.video_tower.video_tower.encoder.layers.21.temporal_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.21.temporal_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.9.temporal_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.11.self_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.18.self_attn.k_proj.bias', 'model.image_tower.image_tower.encoder.layers.8.layer_norm2.bias', 'model.image_tower.image_tower.encoder.layers.22.layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.12.layer_norm2.bias', 'model.video_tower.video_tower.encoder.layers.23.self_attn.out_proj.weight', 'model.image_tower.image_tower.encoder.layers.5.self_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.13.self_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.1.layer_norm2.weight', 'model.video_tower.video_tower.encoder.layers.20.temporal_layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.5.temporal_layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.6.temporal_layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.22.temporal_attn.q_proj.bias', 'model.image_tower.image_tower.encoder.layers.3.mlp.fc1.bias', 'model.video_tower.video_tower.encoder.layers.21.mlp.fc2.bias', 'model.video_tower.video_tower.encoder.layers.18.temporal_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.0.self_attn.k_proj.bias', 'model.image_tower.image_tower.encoder.layers.6.mlp.fc1.bias', 'model.image_tower.image_tower.encoder.layers.11.self_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.4.temporal_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.13.temporal_attn.k_proj.weight', 'model.image_tower.image_tower.encoder.layers.17.self_attn.q_proj.bias', 'model.image_tower.image_tower.encoder.layers.5.mlp.fc2.weight', 'model.video_tower.video_tower.encoder.layers.12.self_attn.out_proj.bias', 'model.image_tower.image_tower.encoder.layers.2.layer_norm1.bias', 'model.image_tower.image_tower.encoder.layers.10.self_attn.out_proj.weight', 'model.image_tower.image_tower.encoder.layers.1.layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.2.temporal_embedding', 'model.video_tower.video_tower.encoder.layers.8.temporal_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.23.self_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.15.layer_norm1.bias', 'model.image_tower.image_tower.encoder.layers.15.mlp.fc1.bias', 'model.image_tower.image_tower.encoder.layers.3.self_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.3.temporal_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.9.mlp.fc2.bias', 'model.image_tower.image_tower.encoder.layers.8.mlp.fc2.weight', 'model.image_tower.image_tower.encoder.layers.21.self_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.14.self_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.17.temporal_layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.5.temporal_embedding', 'model.video_tower.video_tower.encoder.layers.18.mlp.fc2.bias', 'model.video_tower.video_tower.encoder.layers.12.layer_norm1.weight', 'model.image_tower.image_tower.encoder.layers.10.mlp.fc2.weight', 'model.image_tower.image_tower.encoder.layers.1.mlp.fc2.weight', 'model.image_tower.image_tower.encoder.layers.21.self_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.15.mlp.fc1.bias', 'model.image_tower.image_tower.encoder.layers.11.layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.0.temporal_layer_norm1.bias', 'model.image_tower.image_tower.encoder.layers.1.self_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.6.mlp.fc1.bias', 'model.video_tower.video_tower.encoder.layers.4.temporal_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.22.temporal_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.14.layer_norm1.bias', 'model.image_tower.image_tower.encoder.layers.19.self_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.23.self_attn.q_proj.bias', 'model.image_tower.image_tower.encoder.layers.18.self_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.21.mlp.fc2.weight', 'model.video_tower.video_tower.encoder.layers.23.temporal_layer_norm1.bias', 'model.image_tower.image_tower.encoder.layers.18.mlp.fc1.bias', 'model.video_tower.video_tower.encoder.layers.16.temporal_layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.21.layer_norm2.weight', 'model.video_tower.video_tower.encoder.layers.3.self_attn.out_proj.bias', 'model.image_tower.image_tower.encoder.layers.18.layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.23.self_attn.v_proj.bias', 'model.image_tower.image_tower.encoder.layers.15.self_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.9.mlp.fc1.bias', 'model.image_tower.image_tower.encoder.layers.9.self_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.14.self_attn.out_proj.bias', 'model.image_tower.image_tower.encoder.layers.14.self_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.14.temporal_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.5.layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.4.self_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.17.self_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.6.temporal_embedding', 'model.image_tower.image_tower.encoder.layers.0.self_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.6.layer_norm1.weight', 'model.image_tower.image_tower.encoder.layers.20.layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.1.self_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.2.mlp.fc1.weight', 'model.image_tower.image_tower.encoder.layers.9.self_attn.k_proj.weight', 'model.image_tower.image_tower.encoder.layers.22.mlp.fc1.weight', 'model.image_tower.image_tower.encoder.layers.23.self_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.1.temporal_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.22.mlp.fc2.weight', 'model.video_tower.video_tower.encoder.layers.15.temporal_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.3.mlp.fc2.bias', 'model.image_tower.image_tower.encoder.layers.8.self_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.21.layer_norm1.bias', 'model.image_tower.image_tower.encoder.layers.15.self_attn.q_proj.bias', 'model.image_tower.image_tower.encoder.layers.4.self_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.15.layer_norm2.weight', 'model.video_tower.video_tower.encoder.layers.16.mlp.fc1.weight', 'model.video_tower.video_tower.encoder.layers.5.temporal_attn.q_proj.bias', 'model.image_tower.image_tower.encoder.layers.12.layer_norm2.bias', 'model.image_tower.image_tower.encoder.layers.10.self_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.2.temporal_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.6.layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.13.self_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.20.temporal_layer_norm1.bias', 'model.image_tower.image_tower.encoder.layers.6.self_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.21.self_attn.v_proj.weight', 'model.image_tower.image_tower.encoder.layers.3.mlp.fc2.weight', 'model.image_tower.image_tower.encoder.layers.23.mlp.fc1.weight', 'model.image_tower.image_tower.encoder.layers.4.mlp.fc1.weight', 'model.video_tower.video_tower.encoder.layers.20.layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.8.self_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.12.self_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.1.self_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.13.temporal_attn.k_proj.bias', 'model.image_tower.image_tower.encoder.layers.10.self_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.9.layer_norm2.bias', 'model.video_tower.video_tower.encoder.layers.13.mlp.fc2.bias', 'model.video_tower.video_tower.encoder.layers.3.temporal_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.14.temporal_layer_norm1.bias', 'model.image_tower.image_tower.encoder.layers.15.self_attn.v_proj.weight', 'model.image_tower.image_tower.encoder.layers.1.self_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.15.self_attn.v_proj.weight', 'model.image_tower.image_tower.encoder.layers.19.self_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.2.temporal_attn.v_proj.weight', 'model.image_tower.image_tower.encoder.layers.19.self_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.17.temporal_layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.16.self_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.13.mlp.fc1.bias', 'model.image_tower.image_tower.encoder.layers.11.mlp.fc1.weight', 'model.video_tower.video_tower.encoder.layers.13.self_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.10.self_attn.q_proj.bias', 'model.image_tower.image_tower.encoder.layers.0.mlp.fc1.bias', 'model.image_tower.image_tower.encoder.layers.14.layer_norm2.weight', 'model.video_tower.video_tower.encoder.layers.6.mlp.fc1.weight', 'model.video_tower.video_tower.encoder.layers.15.layer_norm2.bias', 'model.image_tower.image_tower.encoder.layers.21.self_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.19.layer_norm2.bias', 'model.video_tower.video_tower.encoder.layers.10.temporal_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.19.temporal_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.8.temporal_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.15.temporal_attn.k_proj.weight', 'model.image_tower.image_tower.encoder.layers.12.mlp.fc1.bias', 'model.video_tower.video_tower.encoder.layers.8.mlp.fc2.bias', 'model.image_tower.image_tower.encoder.layers.18.self_attn.out_proj.bias', 'model.image_tower.image_tower.encoder.layers.3.self_attn.out_proj.weight', 'model.image_tower.image_tower.encoder.layers.12.self_attn.v_proj.bias', 'model.image_tower.image_tower.encoder.layers.7.self_attn.v_proj.weight', 'model.image_tower.image_tower.encoder.layers.3.layer_norm2.bias', 'model.image_tower.image_tower.encoder.layers.22.self_attn.q_proj.weight', 'model.image_tower.image_tower.encoder.layers.5.self_attn.out_proj.weight', 'model.image_tower.image_tower.encoder.layers.4.self_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.15.temporal_layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.11.mlp.fc1.bias', 'model.image_tower.image_tower.encoder.layers.1.mlp.fc2.bias', 'model.video_tower.video_tower.encoder.layers.17.mlp.fc2.weight', 'model.video_tower.video_tower.encoder.layers.2.temporal_layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.10.temporal_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.22.temporal_attn.v_proj.bias', 'model.image_tower.image_tower.encoder.layers.2.mlp.fc1.bias', 'model.image_tower.image_tower.encoder.layers.4.layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.1.layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.10.self_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.7.temporal_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.9.temporal_layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.18.self_attn.k_proj.weight', 'model.image_tower.image_tower.encoder.layers.20.layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.14.self_attn.k_proj.bias', 'model.video_tower.video_tower.post_layernorm.weight', 'model.video_tower.video_tower.encoder.layers.0.temporal_attn.k_proj.weight', 'model.image_tower.image_tower.encoder.layers.21.layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.18.temporal_attn.out_proj.bias', 'model.image_tower.image_tower.encoder.layers.14.self_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.0.temporal_layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.1.temporal_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.12.temporal_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.23.mlp.fc2.weight', 'model.image_tower.image_tower.encoder.layers.13.layer_norm2.weight', 'model.video_tower.video_tower.encoder.layers.23.mlp.fc2.bias', 'model.video_tower.video_tower.encoder.layers.16.temporal_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.16.self_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.7.self_attn.v_proj.bias', 'model.image_tower.image_tower.encoder.layers.5.self_attn.out_proj.bias', 'model.image_tower.image_tower.encoder.layers.4.self_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.12.layer_norm2.weight', 'model.video_tower.video_tower.encoder.layers.10.temporal_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.18.mlp.fc1.bias', 'model.video_tower.video_tower.encoder.layers.11.layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.12.temporal_attn.v_proj.bias', 'model.image_tower.image_tower.encoder.layers.6.layer_norm2.bias', 'model.image_tower.image_tower.encoder.layers.20.mlp.fc1.weight', 'model.image_tower.image_tower.encoder.layers.0.self_attn.k_proj.bias', 'model.image_tower.image_tower.encoder.layers.5.mlp.fc1.weight', 'model.image_tower.image_tower.encoder.layers.23.layer_norm1.bias', 'model.image_tower.image_tower.encoder.layers.8.layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.22.self_attn.q_proj.weight', 'model.image_tower.image_tower.encoder.layers.0.self_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.20.mlp.fc1.bias', 'model.video_tower.video_tower.encoder.layers.21.layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.0.mlp.fc1.bias', 'model.video_tower.video_tower.encoder.layers.2.self_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.3.self_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.20.temporal_attn.k_proj.bias', 'model.image_tower.image_tower.encoder.layers.23.mlp.fc1.bias', 'model.video_tower.video_tower.encoder.layers.0.layer_norm1.weight', 'model.image_tower.image_tower.encoder.layers.19.self_attn.q_proj.weight', 'model.image_tower.image_tower.encoder.layers.2.layer_norm1.weight', 'model.image_tower.image_tower.encoder.layers.15.self_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.6.temporal_attn.out_proj.bias', 'model.image_tower.image_tower.encoder.layers.11.self_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.21.self_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.12.temporal_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.20.self_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.2.self_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.6.self_attn.q_proj.weight', 'model.image_tower.image_tower.encoder.layers.16.layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.7.self_attn.k_proj.bias', 'model.image_tower.image_tower.encoder.layers.9.mlp.fc2.weight', 'model.image_tower.image_tower.encoder.layers.13.self_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.18.temporal_layer_norm1.weight', 'model.image_tower.image_tower.encoder.layers.17.self_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.18.temporal_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.19.mlp.fc2.bias', 'model.image_tower.image_tower.encoder.layers.0.self_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.0.temporal_embedding', 'model.video_tower.video_tower.encoder.layers.23.self_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.9.temporal_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.5.temporal_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.14.temporal_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.22.self_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.3.self_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.7.self_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.13.mlp.fc2.weight', 'model.video_tower.video_tower.encoder.layers.5.self_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.1.self_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.14.temporal_layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.20.mlp.fc2.bias', 'model.video_tower.video_tower.encoder.layers.23.layer_norm1.bias', 'model.image_tower.image_tower.encoder.layers.10.mlp.fc1.weight', 'model.image_tower.image_tower.encoder.layers.3.self_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.16.temporal_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.18.temporal_attn.v_proj.bias', 'model.image_tower.image_tower.encoder.layers.13.self_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.21.mlp.fc1.bias', 'model.video_tower.video_tower.encoder.layers.2.layer_norm2.bias', 'model.image_tower.image_tower.encoder.layers.11.self_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.17.temporal_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.3.temporal_attn.out_proj.bias', 'model.image_tower.image_tower.encoder.layers.2.layer_norm2.weight', 'model.video_tower.video_tower.encoder.layers.9.temporal_embedding', 'model.video_tower.video_tower.encoder.layers.0.temporal_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.10.temporal_attn.v_proj.weight', 'model.image_tower.image_tower.encoder.layers.15.mlp.fc2.bias', 'model.image_tower.image_tower.encoder.layers.6.self_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.0.temporal_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.4.mlp.fc1.bias', 'model.video_tower.video_tower.encoder.layers.14.layer_norm2.weight', 'model.video_tower.video_tower.encoder.layers.2.temporal_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.12.self_attn.v_proj.bias', 'model.image_tower.image_tower.encoder.layers.12.self_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.17.mlp.fc2.bias', 'model.video_tower.video_tower.encoder.layers.16.layer_norm1.weight', 'model.image_tower.image_tower.encoder.layers.22.layer_norm2.bias', 'model.image_tower.image_tower.encoder.layers.1.self_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.19.temporal_embedding', 'model.video_tower.video_tower.encoder.layers.11.self_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.13.temporal_layer_norm1.bias', 'model.image_tower.image_tower.encoder.layers.15.layer_norm1.weight', 'model.image_tower.image_tower.encoder.layers.0.self_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.2.mlp.fc2.weight', 'model.video_tower.video_tower.encoder.layers.4.self_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.8.self_attn.out_proj.bias', 'model.image_tower.image_tower.encoder.layers.11.layer_norm2.weight', 'model.video_tower.video_tower.encoder.layers.5.temporal_layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.3.temporal_attn.k_proj.bias', 'model.image_tower.image_tower.encoder.layers.7.layer_norm2.bias', 'model.video_tower.video_tower.encoder.layers.6.temporal_layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.7.temporal_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.21.mlp.fc1.weight', 'model.video_tower.video_tower.encoder.layers.3.self_attn.k_proj.weight', 'model.image_tower.image_tower.encoder.layers.18.self_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.1.layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.7.self_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.17.temporal_embedding', 'model.video_tower.video_tower.encoder.layers.18.temporal_embedding', 'model.video_tower.video_tower.encoder.layers.2.mlp.fc2.bias', 'model.video_tower.video_tower.encoder.layers.9.layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.22.temporal_layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.9.self_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.0.temporal_attn.q_proj.weight', 'model.image_tower.image_tower.encoder.layers.8.mlp.fc1.bias', 'model.video_tower.video_tower.encoder.layers.7.temporal_attn.q_proj.weight', 'model.image_tower.image_tower.encoder.layers.15.layer_norm2.bias', 'model.image_tower.image_tower.encoder.layers.4.self_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.7.mlp.fc2.bias', 'model.video_tower.video_tower.encoder.layers.11.layer_norm2.weight', 'model.video_tower.video_tower.encoder.layers.13.temporal_attn.q_proj.bias', 'model.image_tower.image_tower.encoder.layers.18.self_attn.q_proj.weight', 'model.image_tower.image_tower.encoder.layers.6.self_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.13.temporal_attn.out_proj.weight', 'model.image_tower.image_tower.encoder.layers.4.layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.5.layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.6.temporal_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.3.mlp.fc1.weight', 'model.video_tower.video_tower.encoder.layers.6.temporal_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.11.self_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.10.layer_norm2.weight', 'model.video_tower.video_tower.encoder.layers.14.self_attn.v_proj.weight', 'model.image_tower.image_tower.encoder.layers.1.self_attn.k_proj.bias', 'model.image_tower.image_tower.encoder.layers.7.self_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.6.temporal_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.5.temporal_attn.out_proj.weight', 'model.image_tower.image_tower.encoder.layers.15.self_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.6.self_attn.out_proj.weight', 'model.image_tower.image_tower.encoder.layers.9.self_attn.out_proj.weight', 'model.image_tower.image_tower.encoder.layers.3.self_attn.v_proj.bias', 'model.image_tower.image_tower.encoder.layers.21.self_attn.out_proj.weight', 'model.image_tower.image_tower.encoder.layers.1.self_attn.out_proj.weight', 'model.image_tower.image_tower.encoder.layers.14.self_attn.out_proj.weight', 'model.image_tower.image_tower.encoder.layers.8.mlp.fc2.bias', 'model.video_tower.video_tower.encoder.layers.3.temporal_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.21.temporal_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.6.self_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.6.temporal_attn.k_proj.weight', 'model.image_tower.image_tower.encoder.layers.0.layer_norm2.weight', 'model.image_tower.image_tower.encoder.layers.11.mlp.fc2.weight', 'model.image_tower.image_tower.encoder.layers.13.self_attn.q_proj.weight', 'model.image_tower.image_tower.encoder.layers.9.self_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.2.self_attn.q_proj.weight', 'model.image_tower.image_tower.encoder.layers.2.self_attn.q_proj.bias', 'model.image_tower.image_tower.encoder.layers.22.layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.10.layer_norm2.bias', 'model.image_tower.image_tower.encoder.layers.22.self_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.5.self_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.19.temporal_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.18.self_attn.out_proj.weight', 'model.image_tower.image_tower.encoder.layers.19.self_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.19.temporal_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.11.temporal_layer_norm1.bias', 'model.image_tower.image_tower.encoder.layers.16.self_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.9.mlp.fc1.weight', 'model.image_tower.image_tower.encoder.layers.23.self_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.22.layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.23.temporal_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.9.temporal_attn.v_proj.bias', 'model.image_tower.image_tower.encoder.layers.3.layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.15.temporal_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.14.mlp.fc1.bias', 'model.video_tower.video_tower.encoder.layers.21.self_attn.k_proj.weight', 'model.image_tower.image_tower.encoder.layers.1.mlp.fc1.bias', 'model.video_tower.video_tower.encoder.layers.18.temporal_layer_norm1.bias', 'model.image_tower.image_tower.encoder.layers.2.self_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.6.temporal_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.9.self_attn.v_proj.weight', 'model.image_tower.image_tower.encoder.layers.0.layer_norm1.weight', 'model.image_tower.image_tower.encoder.layers.19.self_attn.out_proj.weight', 'model.image_tower.image_tower.encoder.layers.22.self_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.17.self_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.21.temporal_embedding', 'model.image_tower.image_tower.encoder.layers.10.layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.12.self_attn.q_proj.bias', 'model.image_tower.image_tower.encoder.layers.14.self_attn.q_proj.bias', 'model.image_tower.image_tower.encoder.layers.17.mlp.fc1.weight', 'model.image_tower.image_tower.encoder.layers.18.mlp.fc2.bias', 'model.image_tower.image_tower.encoder.layers.8.self_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.3.temporal_layer_norm1.bias', 'model.image_tower.image_tower.encoder.layers.13.layer_norm1.bias', 'model.image_tower.image_tower.encoder.layers.13.mlp.fc1.weight', 'model.image_tower.image_tower.encoder.layers.0.self_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.20.temporal_embedding', 'model.video_tower.video_tower.encoder.layers.16.temporal_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.11.self_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.17.layer_norm2.weight', 'model.image_tower.image_tower.encoder.layers.2.mlp.fc2.bias', 'model.image_tower.image_tower.encoder.layers.5.self_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.15.temporal_embedding', 'model.video_tower.video_tower.encoder.layers.15.self_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.2.temporal_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.17.layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.10.temporal_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.15.self_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.23.temporal_attn.k_proj.weight', 'model.image_tower.image_tower.embeddings.position_embedding.weight', 'model.image_tower.image_tower.encoder.layers.7.mlp.fc1.weight', 'model.video_tower.video_tower.encoder.layers.15.temporal_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.1.mlp.fc2.bias', 'model.image_tower.image_tower.encoder.layers.6.self_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.16.temporal_layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.17.temporal_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.7.temporal_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.22.temporal_embedding', 'model.video_tower.video_tower.encoder.layers.12.temporal_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.0.self_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.0.self_attn.q_proj.weight', 'model.image_tower.image_tower.encoder.layers.19.mlp.fc1.bias', 'model.image_tower.image_tower.encoder.layers.7.self_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.18.self_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.23.temporal_attn.out_proj.bias', 'model.image_tower.image_tower.encoder.layers.0.mlp.fc2.bias', 'model.video_tower.video_tower.encoder.layers.5.self_attn.k_proj.weight', 'model.image_tower.image_tower.encoder.layers.9.layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.10.self_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.23.temporal_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.13.temporal_attn.v_proj.weight', 'model.image_tower.image_tower.encoder.layers.0.mlp.fc1.weight', 'model.image_tower.image_tower.encoder.layers.22.self_attn.v_proj.bias', 'model.image_tower.image_tower.encoder.layers.21.self_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.17.self_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.13.temporal_layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.23.temporal_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.10.layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.20.layer_norm2.weight', 'model.image_tower.image_tower.encoder.layers.14.mlp.fc2.bias', 'model.video_tower.video_tower.encoder.layers.7.temporal_layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.5.mlp.fc1.bias', 'model.video_tower.video_tower.encoder.layers.16.self_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.15.layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.9.self_attn.v_proj.bias', 'model.image_tower.image_tower.encoder.layers.11.mlp.fc2.bias', 'model.image_tower.image_tower.encoder.layers.13.self_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.19.self_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.0.self_attn.k_proj.weight', 'model.image_tower.image_tower.encoder.layers.12.self_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.2.self_attn.k_proj.bias', 'model.image_tower.image_tower.encoder.layers.18.mlp.fc1.weight', 'model.video_tower.video_tower.encoder.layers.5.self_attn.q_proj.weight', 'model.image_tower.image_tower.encoder.layers.20.self_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.1.mlp.fc1.weight', 'model.video_tower.video_tower.encoder.layers.7.layer_norm1.weight', 'model.image_tower.image_tower.encoder.layers.0.self_attn.v_proj.weight', 'model.image_tower.image_tower.encoder.layers.22.self_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.22.layer_norm2.bias', 'model.video_tower.video_tower.encoder.layers.3.self_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.0.mlp.fc2.bias', 'model.image_tower.image_tower.encoder.layers.10.self_attn.q_proj.bias', 'model.image_tower.image_tower.encoder.layers.10.mlp.fc1.bias', 'model.image_tower.image_tower.encoder.layers.11.self_attn.k_proj.bias', 'model.image_tower.image_tower.encoder.layers.9.layer_norm2.bias', 'model.image_tower.image_tower.encoder.layers.12.self_attn.q_proj.weight', 'model.image_tower.image_tower.encoder.layers.10.self_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.1.temporal_layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.16.temporal_embedding', 'model.video_tower.video_tower.encoder.layers.13.layer_norm2.weight', 'model.video_tower.video_tower.encoder.layers.6.self_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.8.layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.13.temporal_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.22.layer_norm1.bias', 'model.image_tower.image_tower.encoder.layers.19.self_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.12.layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.18.mlp.fc2.weight', 'model.video_tower.video_tower.encoder.layers.15.mlp.fc2.bias', 'model.video_tower.video_tower.encoder.layers.10.self_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.17.self_attn.v_proj.bias', 'model.image_tower.image_tower.encoder.layers.2.self_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.14.self_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.8.self_attn.k_proj.weight', 'model.image_tower.image_tower.encoder.layers.12.self_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.13.temporal_attn.q_proj.weight', 'model.image_tower.image_tower.encoder.layers.21.mlp.fc2.bias', 'model.image_tower.image_tower.encoder.layers.5.layer_norm2.bias', 'model.video_tower.video_tower.encoder.layers.12.temporal_layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.23.layer_norm2.bias', 'model.image_tower.image_tower.encoder.layers.17.mlp.fc2.weight', 'model.video_tower.video_tower.encoder.layers.19.self_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.10.self_attn.out_proj.weight', 'model.image_tower.image_tower.encoder.layers.16.mlp.fc1.bias', 'model.video_tower.video_tower.encoder.layers.8.temporal_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.2.temporal_attn.out_proj.weight', 'model.image_tower.image_tower.encoder.layers.11.layer_norm2.bias', 'model.image_tower.image_tower.encoder.layers.22.self_attn.v_proj.weight', 'model.image_tower.image_tower.encoder.layers.19.mlp.fc2.bias', 'model.image_tower.image_tower.encoder.layers.23.self_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.1.layer_norm2.bias', 'model.video_tower.video_tower.encoder.layers.5.temporal_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.16.mlp.fc2.bias', 'model.video_tower.video_tower.encoder.layers.7.mlp.fc1.bias', 'model.video_tower.video_tower.encoder.layers.11.temporal_layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.21.self_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.7.temporal_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.12.temporal_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.5.self_attn.q_proj.bias', 'model.image_tower.image_tower.encoder.layers.15.layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.10.temporal_embedding', 'model.image_tower.image_tower.encoder.layers.12.mlp.fc1.weight', 'model.video_tower.video_tower.encoder.layers.1.temporal_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.14.mlp.fc2.bias', 'model.video_tower.video_tower.encoder.layers.16.temporal_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.18.temporal_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.1.temporal_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.20.temporal_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.10.temporal_layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.8.temporal_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.18.self_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.19.temporal_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.12.temporal_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.7.temporal_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.2.self_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.20.layer_norm2.bias', 'model.image_tower.image_tower.encoder.layers.2.self_attn.k_proj.weight', 'model.image_tower.image_tower.encoder.layers.20.self_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.23.self_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.0.layer_norm2.bias', 'model.image_tower.image_tower.encoder.layers.21.mlp.fc1.bias', 'model.image_tower.image_tower.encoder.layers.5.layer_norm2.weight', 'model.video_tower.video_tower.encoder.layers.10.mlp.fc1.weight', 'model.video_tower.video_tower.encoder.layers.13.self_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.14.layer_norm2.bias', 'model.video_tower.video_tower.encoder.layers.2.self_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.3.mlp.fc1.bias', 'model.video_tower.video_tower.encoder.layers.22.self_attn.v_proj.weight', 'model.video_tower.video_tower.embeddings.patch_embedding.weight', 'model.video_tower.video_tower.encoder.layers.11.mlp.fc1.weight', 'model.image_tower.image_tower.encoder.layers.10.self_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.22.temporal_attn.out_proj.bias', 'model.image_tower.image_tower.encoder.layers.20.mlp.fc2.bias', 'model.video_tower.video_tower.encoder.layers.9.temporal_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.1.temporal_attn.v_proj.weight', 'model.image_tower.image_tower.encoder.layers.22.mlp.fc2.weight', 'model.image_tower.image_tower.encoder.layers.8.layer_norm2.weight', 'model.video_tower.video_tower.encoder.layers.10.temporal_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.18.temporal_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.5.temporal_attn.v_proj.weight', 'model.image_tower.image_tower.encoder.layers.9.self_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.21.temporal_layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.21.layer_norm2.bias', 'model.video_tower.video_tower.encoder.layers.10.self_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.7.mlp.fc2.weight', 'model.image_tower.image_tower.encoder.layers.19.layer_norm2.bias', 'model.video_tower.video_tower.encoder.layers.21.temporal_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.19.mlp.fc1.bias', 'model.image_tower.image_tower.encoder.layers.23.mlp.fc2.weight', 'model.image_tower.image_tower.encoder.layers.16.mlp.fc2.bias', 'model.image_tower.image_tower.encoder.layers.8.self_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.4.self_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.4.temporal_layer_norm1.weight', 'model.image_tower.image_tower.encoder.layers.0.self_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.13.self_attn.k_proj.weight', 'model.image_tower.image_tower.encoder.layers.7.layer_norm1.bias', 'model.image_tower.image_tower.encoder.layers.17.self_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.5.mlp.fc2.weight', 'model.video_tower.video_tower.encoder.layers.5.mlp.fc2.bias', 'model.image_tower.image_tower.encoder.layers.8.self_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.2.self_attn.v_proj.weight', 'model.image_tower.image_tower.encoder.layers.17.layer_norm1.weight', 'model.image_tower.image_tower.encoder.layers.13.mlp.fc2.bias', 'model.image_tower.image_tower.encoder.layers.4.mlp.fc2.bias', 'model.video_tower.video_tower.encoder.layers.20.self_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.7.layer_norm2.weight', 'model.video_tower.video_tower.encoder.layers.13.self_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.13.temporal_embedding', 'model.video_tower.video_tower.encoder.layers.23.temporal_attn.out_proj.weight', 'model.image_tower.image_tower.encoder.layers.18.layer_norm2.weight', 'model.video_tower.video_tower.encoder.layers.22.temporal_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.7.layer_norm2.bias', 'model.video_tower.video_tower.encoder.layers.15.temporal_attn.v_proj.bias', 'model.image_tower.image_tower.encoder.layers.1.layer_norm2.weight', 'model.video_tower.video_tower.encoder.layers.20.self_attn.out_proj.bias', 'model.image_tower.image_tower.encoder.layers.6.self_attn.q_proj.bias', 'model.image_tower.image_tower.encoder.layers.4.layer_norm2.weight', 'model.image_tower.image_tower.encoder.layers.18.layer_norm1.bias', 'model.image_tower.image_tower.encoder.layers.13.mlp.fc2.weight', 'model.image_tower.image_tower.encoder.layers.9.layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.11.temporal_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.2.layer_norm1.weight', 'model.image_tower.image_tower.encoder.layers.6.layer_norm2.weight', 'model.image_tower.image_tower.pre_layrnorm.bias', 'model.image_tower.image_tower.encoder.layers.10.layer_norm2.bias', 'model.image_tower.image_tower.encoder.layers.1.layer_norm1.weight', 'model.image_tower.image_tower.encoder.layers.3.mlp.fc1.weight', 'model.video_tower.video_tower.encoder.layers.20.self_attn.out_proj.weight', 'model.image_tower.image_tower.encoder.layers.10.self_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.16.layer_norm2.weight', 'model.video_tower.video_tower.encoder.layers.23.layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.2.temporal_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.8.temporal_layer_norm1.weight', 'model.image_tower.image_tower.encoder.layers.8.mlp.fc1.weight', 'model.video_tower.video_tower.encoder.layers.3.layer_norm2.bias', 'model.video_tower.video_tower.encoder.layers.7.self_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.9.mlp.fc2.weight', 'model.video_tower.video_tower.encoder.layers.9.temporal_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.23.self_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.9.temporal_layer_norm1.bias', 'model.image_tower.image_tower.encoder.layers.20.mlp.fc2.weight', 'model.video_tower.video_tower.pre_layrnorm.weight', 'model.video_tower.video_tower.encoder.layers.21.self_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.16.self_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.1.mlp.fc2.weight', 'model.video_tower.video_tower.encoder.layers.5.self_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.6.self_attn.v_proj.bias', 'model.image_tower.image_tower.encoder.layers.14.layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.1.temporal_attn.q_proj.bias', 'model.image_tower.image_tower.encoder.layers.18.self_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.6.temporal_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.11.temporal_embedding', 'model.image_tower.image_tower.encoder.layers.22.mlp.fc2.bias', 'model.image_tower.image_tower.encoder.layers.8.self_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.22.mlp.fc2.bias', 'model.video_tower.video_tower.encoder.layers.5.temporal_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.18.mlp.fc1.weight', 'model.video_tower.video_tower.encoder.layers.20.self_attn.q_proj.weight', 'model.image_tower.image_tower.encoder.layers.9.self_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.19.self_attn.q_proj.weight', 'model.image_tower.image_tower.encoder.layers.15.self_attn.k_proj.bias', 'model.image_tower.image_tower.encoder.layers.20.layer_norm2.bias', 'model.video_tower.video_tower.encoder.layers.13.self_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.9.self_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.12.temporal_embedding', 'model.image_tower.image_tower.encoder.layers.15.self_attn.q_proj.weight', 'model.image_tower.image_tower.encoder.layers.21.self_attn.k_proj.weight', 'model.image_tower.image_tower.encoder.layers.19.layer_norm1.weight', 'model.image_tower.image_tower.encoder.layers.20.self_attn.q_proj.bias', 'model.image_tower.image_tower.encoder.layers.17.mlp.fc1.bias', 'model.video_tower.video_tower.encoder.layers.11.self_attn.out_proj.weight', 'model.image_tower.image_tower.encoder.layers.17.self_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.4.mlp.fc1.weight', 'model.video_tower.video_tower.post_layernorm.bias', 'model.video_tower.video_tower.encoder.layers.22.self_attn.k_proj.weight', 'model.image_tower.image_tower.encoder.layers.12.self_attn.v_proj.weight', 'model.image_tower.image_tower.encoder.layers.6.mlp.fc1.weight', 'model.video_tower.video_tower.encoder.layers.14.temporal_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.3.self_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.20.mlp.fc1.weight', 'model.video_tower.video_tower.encoder.layers.4.temporal_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.8.self_attn.q_proj.weight', 'model.image_tower.image_tower.encoder.layers.14.self_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.23.self_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.0.self_attn.v_proj.weight', 'model.image_tower.image_tower.encoder.layers.5.layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.16.temporal_attn.out_proj.bias', 'model.image_tower.image_tower.encoder.layers.16.self_attn.v_proj.weight', 'model.image_tower.image_tower.encoder.layers.1.self_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.1.self_attn.v_proj.weight', 'model.image_tower.image_tower.encoder.layers.10.layer_norm2.weight', 'model.video_tower.video_tower.encoder.layers.17.layer_norm1.bias', 'model.image_tower.image_tower.encoder.layers.17.self_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.0.mlp.fc1.weight', 'model.video_tower.video_tower.encoder.layers.4.self_attn.out_proj.bias', 'model.image_tower.image_tower.encoder.layers.20.self_attn.v_proj.weight', 'model.image_tower.image_tower.encoder.layers.17.self_attn.v_proj.weight', 'model.image_tower.image_tower.encoder.layers.23.self_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.3.temporal_attn.k_proj.weight', 'model.image_tower.image_tower.encoder.layers.7.self_attn.k_proj.bias', 'model.image_tower.image_tower.encoder.layers.1.layer_norm2.bias', 'model.image_tower.image_tower.encoder.layers.14.layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.12.self_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.13.layer_norm2.bias', 'model.video_tower.video_tower.encoder.layers.19.layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.9.self_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.2.temporal_layer_norm1.weight', 'model.image_tower.image_tower.encoder.layers.6.self_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.12.mlp.fc2.weight', 'model.video_tower.video_tower.encoder.layers.21.temporal_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.8.temporal_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.11.self_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.9.self_attn.out_proj.bias', 'model.image_tower.image_tower.encoder.layers.8.layer_norm1.weight', 'model.image_tower.image_tower.encoder.layers.3.self_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.11.temporal_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.22.self_attn.k_proj.bias', 'model.image_tower.image_tower.encoder.layers.23.self_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.7.temporal_layer_norm1.weight', 'model.image_tower.image_tower.encoder.layers.2.self_attn.k_proj.bias', 'model.image_tower.image_tower.encoder.layers.6.self_attn.v_proj.bias', 'model.image_tower.image_tower.encoder.layers.7.layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.20.temporal_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.11.mlp.fc2.bias', 'model.video_tower.video_tower.encoder.layers.14.temporal_attn.q_proj.bias', 'model.image_tower.image_tower.encoder.layers.14.mlp.fc2.weight', 'model.video_tower.video_tower.encoder.layers.8.mlp.fc1.bias', 'model.image_tower.image_tower.encoder.layers.23.self_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.4.temporal_attn.v_proj.weight', 'model.image_tower.image_tower.encoder.layers.16.self_attn.k_proj.bias', 'model.image_tower.image_tower.encoder.layers.22.self_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.3.temporal_layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.3.mlp.fc2.weight', 'model.image_tower.image_tower.encoder.layers.7.mlp.fc2.bias', 'model.image_tower.image_tower.encoder.layers.4.mlp.fc2.weight', 'model.video_tower.video_tower.encoder.layers.3.self_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.15.temporal_layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.20.self_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.3.layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.21.temporal_layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.23.temporal_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.2.temporal_attn.k_proj.bias', 'model.image_tower.image_tower.encoder.layers.12.mlp.fc2.bias', 'model.video_tower.video_tower.encoder.layers.13.layer_norm1.weight', 'model.image_tower.image_tower.encoder.layers.17.layer_norm2.weight', 'model.image_tower.image_tower.encoder.layers.16.self_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.3.layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.11.layer_norm2.bias', 'model.video_tower.video_tower.encoder.layers.5.layer_norm2.bias', 'model.image_tower.image_tower.encoder.layers.3.mlp.fc2.bias', 'model.video_tower.video_tower.encoder.layers.0.temporal_attn.out_proj.weight', 'model.image_tower.image_tower.encoder.layers.11.self_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.19.self_attn.q_proj.bias', 'model.image_tower.image_tower.encoder.layers.22.mlp.fc1.bias', 'model.video_tower.video_tower.encoder.layers.15.self_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.16.layer_norm2.bias', 'model.video_tower.video_tower.encoder.layers.16.self_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.18.self_attn.q_proj.bias', 'model.image_tower.image_tower.encoder.layers.5.mlp.fc1.bias', 'model.image_tower.image_tower.encoder.layers.20.self_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.13.self_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.3.temporal_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.13.layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.4.mlp.fc2.bias', 'model.video_tower.video_tower.encoder.layers.12.temporal_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.10.temporal_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.7.self_attn.out_proj.weight', 'model.image_tower.image_tower.encoder.layers.5.self_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.8.temporal_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.19.temporal_layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.20.temporal_attn.k_proj.weight', 'model.image_tower.image_tower.encoder.layers.1.self_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.16.self_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.1.temporal_layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.8.self_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.14.mlp.fc2.weight', 'model.video_tower.video_tower.encoder.layers.15.temporal_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.8.layer_norm2.bias', 'model.image_tower.image_tower.encoder.layers.7.self_attn.q_proj.weight', 'model.image_tower.image_tower.encoder.layers.13.self_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.8.temporal_embedding', 'model.video_tower.video_tower.encoder.layers.17.temporal_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.17.temporal_attn.v_proj.weight', 'model.image_tower.image_tower.encoder.layers.13.mlp.fc1.bias', 'model.video_tower.video_tower.encoder.layers.17.mlp.fc1.bias', 'model.video_tower.video_tower.encoder.layers.8.self_attn.v_proj.weight', 'model.video_tower.video_tower.embeddings.position_embedding.weight', 'model.image_tower.image_tower.encoder.layers.9.mlp.fc1.weight', 'model.video_tower.video_tower.encoder.layers.0.layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.11.temporal_attn.v_proj.bias', 'model.image_tower.image_tower.encoder.layers.4.self_attn.v_proj.bias', 'model.image_tower.image_tower.encoder.layers.6.layer_norm1.weight', 'model.image_tower.image_tower.encoder.layers.21.layer_norm2.weight', 'model.video_tower.video_tower.encoder.layers.20.self_attn.k_proj.weight', 'model.image_tower.image_tower.encoder.layers.21.mlp.fc1.weight', 'model.image_tower.image_tower.encoder.layers.6.mlp.fc2.weight', 'model.image_tower.image_tower.encoder.layers.5.mlp.fc2.bias', 'model.video_tower.video_tower.encoder.layers.8.layer_norm1.weight', 'model.image_tower.image_tower.encoder.layers.18.layer_norm2.bias', 'model.image_tower.image_tower.encoder.layers.23.layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.14.self_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.4.layer_norm1.bias', 'model.image_tower.image_tower.encoder.layers.9.layer_norm2.weight', 'model.image_tower.image_tower.encoder.layers.15.layer_norm2.weight', 'model.video_tower.video_tower.encoder.layers.16.temporal_attn.k_proj.bias', 'model.image_tower.image_tower.encoder.layers.9.self_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.17.temporal_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.0.mlp.fc2.weight', 'model.image_tower.image_tower.encoder.layers.16.mlp.fc1.weight', 'model.video_tower.video_tower.encoder.layers.0.temporal_attn.k_proj.bias', 'model.image_tower.image_tower.encoder.layers.20.mlp.fc1.bias', 'model.video_tower.video_tower.encoder.layers.5.layer_norm2.weight', 'model.image_tower.image_tower.encoder.layers.10.self_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.3.layer_norm2.weight', 'model.video_tower.video_tower.encoder.layers.8.self_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.20.temporal_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.19.layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.4.self_attn.q_proj.weight', 'model.image_tower.image_tower.encoder.layers.14.layer_norm2.bias', 'model.image_tower.image_tower.encoder.layers.12.self_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.19.mlp.fc1.weight', 'model.video_tower.video_tower.encoder.layers.11.self_attn.k_proj.bias', 'model.image_tower.image_tower.encoder.layers.10.layer_norm1.bias', 'model.image_tower.image_tower.encoder.layers.16.self_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.1.temporal_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.12.mlp.fc1.weight', 'model.video_tower.video_tower.pre_layrnorm.bias', 'model.video_tower.video_tower.encoder.layers.12.self_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.0.temporal_attn.v_proj.bias', 'model.image_tower.image_tower.encoder.layers.13.layer_norm2.bias', 'model.video_tower.video_tower.encoder.layers.20.self_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.0.temporal_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.15.self_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.17.self_attn.v_proj.weight', 'model.image_tower.image_tower.encoder.layers.16.layer_norm2.bias', 'model.video_tower.video_tower.encoder.layers.8.temporal_layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.4.temporal_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.0.self_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.22.self_attn.v_proj.bias', 'model.image_tower.image_tower.encoder.layers.6.self_attn.k_proj.bias', 'model.image_tower.image_tower.encoder.layers.1.self_attn.v_proj.bias', 'model.image_tower.image_tower.encoder.layers.23.self_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.18.temporal_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.19.self_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.18.self_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.19.temporal_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.21.self_attn.out_proj.bias', 'model.image_tower.image_tower.encoder.layers.14.self_attn.v_proj.bias', 'model.image_tower.image_tower.encoder.layers.18.self_attn.v_proj.weight', 'model.image_tower.image_tower.encoder.layers.11.mlp.fc1.bias', 'model.image_tower.image_tower.encoder.layers.20.layer_norm2.weight', 'model.image_tower.image_tower.encoder.layers.20.self_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.10.self_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.14.layer_norm1.weight', 'model.image_tower.image_tower.encoder.layers.7.self_attn.out_proj.weight', 'model.image_tower.image_tower.encoder.layers.10.mlp.fc2.bias', 'model.video_tower.video_tower.encoder.layers.10.mlp.fc1.bias', 'model.image_tower.image_tower.encoder.layers.11.self_attn.k_proj.weight', 'model.image_tower.image_tower.encoder.layers.4.self_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.4.temporal_attn.k_proj.bias', 'model.image_tower.image_tower.encoder.layers.15.self_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.19.layer_norm2.weight', 'model.image_tower.image_tower.encoder.layers.5.self_attn.q_proj.bias', 'model.image_tower.image_tower.encoder.layers.15.mlp.fc2.weight', 'model.image_tower.image_tower.encoder.layers.19.mlp.fc1.weight', 'model.image_tower.image_tower.encoder.layers.11.self_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.18.temporal_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.14.temporal_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.9.self_attn.out_proj.weight', 'model.image_tower.image_tower.encoder.layers.7.mlp.fc2.weight', 'model.video_tower.video_tower.encoder.layers.4.temporal_layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.2.mlp.fc1.bias', 'model.video_tower.video_tower.encoder.layers.22.temporal_layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.1.temporal_attn.out_proj.bias', 'model.image_tower.image_tower.post_layernorm.weight', 'model.video_tower.video_tower.encoder.layers.12.temporal_layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.22.temporal_attn.v_proj.weight', 'model.image_tower.image_tower.encoder.layers.19.layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.17.temporal_attn.out_proj.bias', 'model.image_tower.image_tower.embeddings.class_embedding', 'model.video_tower.video_tower.encoder.layers.7.temporal_embedding', 'model.image_tower.image_tower.embeddings.patch_embedding.weight', 'model.image_tower.image_tower.encoder.layers.9.mlp.fc2.bias', 'model.video_tower.video_tower.encoder.layers.19.self_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.4.temporal_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.2.layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.9.temporal_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.10.temporal_layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.8.layer_norm2.weight', 'model.image_tower.image_tower.encoder.layers.4.layer_norm2.bias', 'model.video_tower.video_tower.encoder.layers.18.layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.7.temporal_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.0.layer_norm2.weight', 'model.video_tower.video_tower.encoder.layers.16.mlp.fc1.bias', 'model.image_tower.image_tower.encoder.layers.16.layer_norm2.weight', 'model.image_tower.image_tower.encoder.layers.21.layer_norm2.bias', 'model.video_tower.video_tower.encoder.layers.10.mlp.fc2.bias', 'model.image_tower.image_tower.encoder.layers.14.self_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.3.temporal_embedding', 'model.video_tower.video_tower.encoder.layers.18.self_attn.q_proj.weight', 'model.image_tower.image_tower.encoder.layers.16.self_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.9.layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.6.mlp.fc2.bias', 'model.video_tower.video_tower.encoder.layers.20.temporal_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.20.mlp.fc2.weight', 'model.video_tower.video_tower.encoder.layers.2.layer_norm2.weight', 'model.image_tower.image_tower.encoder.layers.18.self_attn.out_proj.weight', 'model.image_tower.image_tower.encoder.layers.17.self_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.13.temporal_attn.out_proj.bias', 'model.image_tower.image_tower.encoder.layers.12.layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.15.mlp.fc1.weight', 'model.image_tower.image_tower.encoder.layers.4.mlp.fc1.bias', 'model.video_tower.video_tower.encoder.layers.15.temporal_attn.q_proj.weight', 'model.image_tower.image_tower.encoder.layers.5.layer_norm1.weight', 'model.image_tower.image_tower.encoder.layers.2.mlp.fc1.weight', 'model.video_tower.video_tower.encoder.layers.14.temporal_attn.k_proj.bias', 'model.image_tower.image_tower.encoder.layers.2.self_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.14.temporal_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.4.mlp.fc2.weight', 'model.video_tower.video_tower.encoder.layers.7.self_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.20.temporal_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.17.self_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.4.layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.6.layer_norm2.bias', 'model.image_tower.image_tower.encoder.layers.13.self_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.1.self_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.1.self_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.10.mlp.fc2.weight', 'model.video_tower.video_tower.encoder.layers.22.temporal_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.22.self_attn.out_proj.weight', 'model.image_tower.image_tower.encoder.layers.21.mlp.fc2.weight', 'model.video_tower.video_tower.encoder.layers.19.mlp.fc2.weight', 'model.video_tower.video_tower.encoder.layers.15.mlp.fc2.weight', 'model.video_tower.video_tower.encoder.layers.4.self_attn.out_proj.weight', 'model.image_tower.image_tower.encoder.layers.6.layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.10.layer_norm1.bias', 'model.image_tower.image_tower.encoder.layers.16.layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.9.layer_norm2.weight', 'model.image_tower.image_tower.encoder.layers.11.self_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.16.self_attn.out_proj.bias', 'model.image_tower.image_tower.pre_layrnorm.weight', 'model.video_tower.video_tower.encoder.layers.7.layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.2.self_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.11.layer_norm1.bias', 'model.image_tower.image_tower.encoder.layers.21.self_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.9.self_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.14.self_attn.q_proj.bias', 'model.image_tower.image_tower.encoder.layers.1.mlp.fc1.weight', 'model.image_tower.image_tower.encoder.layers.17.self_attn.out_proj.bias', 'model.image_tower.image_tower.encoder.layers.19.layer_norm2.weight', 'model.image_tower.image_tower.encoder.layers.18.mlp.fc2.weight', 'model.image_tower.image_tower.encoder.layers.4.self_attn.k_proj.weight', 'model.image_tower.image_tower.encoder.layers.12.layer_norm2.weight', 'model.video_tower.video_tower.encoder.layers.14.temporal_attn.q_proj.weight', 'model.image_tower.image_tower.encoder.layers.2.mlp.fc2.weight', 'model.video_tower.video_tower.encoder.layers.15.self_attn.k_proj.bias', 'model.image_tower.image_tower.encoder.layers.3.self_attn.out_proj.bias', 'model.video_tower.video_tower.embeddings.class_embedding', 'model.video_tower.video_tower.encoder.layers.5.temporal_attn.k_proj.weight', 'model.image_tower.image_tower.encoder.layers.12.layer_norm1.weight', 'model.image_tower.image_tower.post_layernorm.bias', 'model.video_tower.video_tower.encoder.layers.8.temporal_attn.k_proj.weight', 'model.image_tower.image_tower.encoder.layers.22.self_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.19.temporal_attn.v_proj.bias', 'model.image_tower.image_tower.encoder.layers.18.self_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.15.self_attn.v_proj.bias', 'model.image_tower.image_tower.encoder.layers.17.mlp.fc2.bias', 'model.video_tower.video_tower.encoder.layers.15.self_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.10.self_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.2.temporal_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.0.self_attn.out_proj.bias', 'model.image_tower.image_tower.encoder.layers.20.self_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.21.temporal_attn.out_proj.bias', 'model.image_tower.image_tower.encoder.layers.22.layer_norm2.weight', 'model.image_tower.image_tower.encoder.layers.13.self_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.6.mlp.fc2.weight', 'model.video_tower.video_tower.encoder.layers.4.temporal_embedding', 'model.video_tower.video_tower.encoder.layers.23.mlp.fc1.weight', 'model.image_tower.image_tower.encoder.layers.11.layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.8.temporal_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.7.temporal_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.20.layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.15.temporal_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.14.temporal_embedding', 'model.video_tower.video_tower.encoder.layers.22.temporal_attn.k_proj.weight', 'model.image_tower.image_tower.encoder.layers.3.self_attn.k_proj.weight', 'model.image_tower.image_tower.encoder.layers.5.self_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.16.temporal_attn.out_proj.weight', 'model.image_tower.image_tower.encoder.layers.8.self_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.4.self_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.11.temporal_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.7.mlp.fc1.weight', 'model.image_tower.image_tower.encoder.layers.0.mlp.fc2.weight', 'model.video_tower.video_tower.encoder.layers.11.mlp.fc2.weight', 'model.video_tower.video_tower.encoder.layers.6.self_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.21.self_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.11.temporal_attn.v_proj.weight', 'model.image_tower.image_tower.encoder.layers.5.self_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.22.mlp.fc1.bias', 'model.video_tower.video_tower.encoder.layers.1.self_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.17.temporal_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.16.layer_norm1.bias', 'model.image_tower.image_tower.encoder.layers.7.mlp.fc1.bias', 'model.video_tower.video_tower.encoder.layers.6.self_attn.v_proj.weight', 'model.image_tower.image_tower.encoder.layers.7.self_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.4.layer_norm2.weight', 'model.image_tower.image_tower.encoder.layers.13.layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.21.temporal_attn.out_proj.weight', 'model.image_tower.image_tower.encoder.layers.19.self_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.12.self_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.5.self_attn.v_proj.weight', 'model.image_tower.image_tower.encoder.layers.17.layer_norm2.bias', 'model.video_tower.video_tower.encoder.layers.19.temporal_attn.k_proj.weight', 'model.image_tower.image_tower.encoder.layers.7.self_attn.v_proj.bias', 'model.image_tower.image_tower.encoder.layers.21.self_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.17.layer_norm2.bias', 'model.image_tower.image_tower.encoder.layers.0.layer_norm2.bias', 'model.video_tower.video_tower.encoder.layers.16.mlp.fc2.weight', 'model.video_tower.video_tower.encoder.layers.23.temporal_attn.k_proj.bias', 'model.image_tower.image_tower.encoder.layers.4.self_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.0.self_attn.out_proj.weight', 'model.video_tower.video_tower.encoder.layers.19.self_attn.out_proj.bias', 'model.image_tower.image_tower.encoder.layers.8.self_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.21.temporal_attn.q_proj.weight', 'model.image_tower.image_tower.encoder.layers.12.mlp.fc2.weight', 'model.image_tower.image_tower.encoder.layers.12.self_attn.out_proj.bias', 'model.image_tower.image_tower.encoder.layers.15.mlp.fc1.weight', 'model.video_tower.video_tower.encoder.layers.11.self_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.1.mlp.fc1.bias', 'model.image_tower.image_tower.encoder.layers.19.mlp.fc2.weight', 'model.video_tower.video_tower.encoder.layers.4.layer_norm2.bias', 'model.image_tower.image_tower.encoder.layers.16.self_attn.out_proj.bias', 'model.video_tower.video_tower.encoder.layers.11.temporal_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.14.self_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.3.temporal_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.8.self_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.23.temporal_layer_norm1.weight', 'model.video_tower.video_tower.encoder.layers.22.layer_norm2.weight', 'model.video_tower.video_tower.encoder.layers.17.self_attn.k_proj.weight', 'model.image_tower.image_tower.encoder.layers.14.mlp.fc1.weight', 'model.video_tower.video_tower.encoder.layers.4.temporal_attn.k_proj.weight', 'model.image_tower.image_tower.encoder.layers.14.self_attn.k_proj.weight', 'model.video_tower.video_tower.encoder.layers.17.self_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.13.mlp.fc1.weight', 'model.video_tower.video_tower.encoder.layers.23.layer_norm2.weight', 'model.video_tower.video_tower.encoder.layers.17.mlp.fc1.weight', 'model.video_tower.video_tower.encoder.layers.9.temporal_attn.q_proj.weight', 'model.video_tower.video_tower.encoder.layers.20.temporal_attn.q_proj.bias', 'model.video_tower.video_tower.encoder.layers.10.temporal_attn.k_proj.bias', 'model.video_tower.video_tower.encoder.layers.21.self_attn.out_proj.weight', 'model.image_tower.image_tower.encoder.layers.2.self_attn.v_proj.bias', 'model.image_tower.image_tower.encoder.layers.2.layer_norm2.bias', 'model.video_tower.video_tower.encoder.layers.18.layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.4.self_attn.k_proj.weight', 'model.image_tower.image_tower.encoder.layers.20.self_attn.k_proj.bias', 'model.image_tower.image_tower.encoder.layers.23.mlp.fc2.bias', 'model.image_tower.image_tower.encoder.layers.9.mlp.fc1.bias', 'model.video_tower.video_tower.encoder.layers.19.temporal_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.1.self_attn.v_proj.bias', 'model.video_tower.video_tower.encoder.layers.19.temporal_layer_norm1.bias', 'model.video_tower.video_tower.encoder.layers.12.mlp.fc1.bias', 'model.video_tower.video_tower.encoder.layers.16.self_attn.v_proj.weight', 'model.video_tower.video_tower.encoder.layers.6.temporal_attn.v_proj.bias', 'model.image_tower.image_tower.encoder.layers.3.layer_norm1.bias', 'model.image_tower.image_tower.encoder.layers.6.mlp.fc2.bias', 'model.video_tower.video_tower.encoder.layers.1.temporal_embedding', 'model.image_tower.image_tower.encoder.layers.21.layer_norm1.weight']\n- This IS expected if you are initializing LlavaLlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing LlavaLlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/162 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54fcb9a0093a4c49b68341c96c530167"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.71G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85f67c5f90f345eb89b15447d8e4693d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.11G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72e76df78b314326ba3224fbf59f64de"}},"metadata":{}}]},{"cell_type":"code","source":"def getPrediction(video):\n    inp = f'Which category from this list does the video belong to: {cats}?'\n    \n    video_processor = processor['video']\n    conv_mode = \"llava_v1\"\n    conv = conv_templates[conv_mode].copy()\n    roles = conv.roles\n\n    video_tensor = video_processor(video, return_tensors='pt')['pixel_values']\n    if type(video_tensor) is list:\n        tensor = [video.to(model.device, dtype=torch.float16) for video in video_tensor]\n    else:\n        tensor = video_tensor.to(model.device, dtype=torch.float16)\n        \n    inp = ' '.join([DEFAULT_IMAGE_TOKEN] * model.get_video_tower().config.num_frames) + '\\n' + inp\n\n    conv.append_message(conv.roles[0], inp)\n    conv.append_message(conv.roles[1], None)\n\n    prompt = conv.get_prompt()\n    input_ids = tokenizer_image_token(prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors='pt').unsqueeze(0).cuda()\n\n    stop_str = conv.sep if conv.sep_style != SeparatorStyle.TWO else conv.sep2\n    keywords = [stop_str]\n    stopping_criteria = KeywordsStoppingCriteria(keywords, tokenizer, input_ids)\n\n    with torch.inference_mode():\n        output_ids = model.generate(\n            input_ids,\n            images=tensor,\n            do_sample=True,\n            temperature=0.1,\n            max_new_tokens=16,\n            use_cache=True,\n            stopping_criteria=[stopping_criteria])\n\n    outputs = tokenizer.decode(output_ids[0, input_ids.shape[1]:]).strip()\n\n    return outputs","metadata":{"execution":{"iopub.status.busy":"2024-05-15T11:55:23.624581Z","iopub.execute_input":"2024-05-15T11:55:23.624913Z","iopub.status.idle":"2024-05-15T11:55:23.638991Z","shell.execute_reply.started":"2024-05-15T11:55:23.624886Z","shell.execute_reply":"2024-05-15T11:55:23.637996Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"video = '/kaggle/input/youtube-video-ads/data/domestic_violence/G9ZvxYcPJk8_domestic_violence.mp4'\ngetPrediction(video)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T11:55:58.024613Z","iopub.execute_input":"2024-05-15T11:55:58.025250Z","iopub.status.idle":"2024-05-15T11:56:04.638186Z","shell.execute_reply.started":"2024-05-15T11:55:58.025216Z","shell.execute_reply":"2024-05-15T11:56:04.637186Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"\"The video belongs to the 'domestic_violence' category.</s>\""},"metadata":{}}]}]}